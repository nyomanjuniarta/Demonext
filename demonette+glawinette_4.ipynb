{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc2e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from networkx.algorithms import isomorphism\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f480099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12772221, 1)\n"
     ]
    }
   ],
   "source": [
    "frequencies = pd.read_csv('frequencies-frcowvec-filtered.csv', header=0, index_col=0)\n",
    "print(frequencies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3a756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frcowvec_categories = {'Nm': 'NOM', 'Nf': 'NOM', 'Nmp': 'NOM', 'Nfp': 'NOM', 'Nx': 'NOM', 'More': 'NOM',\n",
    "                       'Npm': 'NAM', 'Npf': 'NAM', 'Npx': 'NAM', 'Npmp': 'NAM', 'Npfp': 'NAM',\n",
    "                       'Adj': 'ADJ', 'V': 'VER', 'Num': 'NUM', 'Pro': 'PRO', 'Adv': 'ADV'}\n",
    "def get_frequency(lex_and_cat):\n",
    "    if '_' not in lex_and_cat:\n",
    "        return 0\n",
    "    old_cat = lex_and_cat.split('_')[-1]\n",
    "    new_cat = frcowvec_categories.get(old_cat)\n",
    "    new_lex_and_cat = lex_and_cat.split('_')[0] + '_' + new_cat\n",
    "    try:\n",
    "        freq = frequencies.loc[new_lex_and_cat]['freq']\n",
    "        return freq\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5546c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonette_lexemes = set()\n",
    "with codecs.open('lexemes.csv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        elements = line.split('\\t')\n",
    "        if elements[0] == 'lid':\n",
    "            continue\n",
    "        demonette_lexemes.add(elements[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d872db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lexeme(a1, a2, b1):  # generate lexeme and it's part-of-speech\n",
    "    a1_lex = '^' + a1.split('_')[0] + '$'\n",
    "    a2_lex = '^' + a2.split('_')[0] + '$'\n",
    "    b1_lex = '^' + b1.split('_')[0] + '$'\n",
    "    a2_cat = a2.split('_')[1]\n",
    "    match = SequenceMatcher(None, a1_lex, a2_lex).find_longest_match(0, len(a1_lex), 0, len(a2_lex))\n",
    "    common = a1_lex[match.a:match.a+match.size]\n",
    "    a1_affix = a1_lex.replace(common, '(.+)')\n",
    "    a2_affix = a2_lex.replace(common, '(.+)')\n",
    "    a1_prefix = a1_affix[1:a1_affix.index('(')]\n",
    "    a1_postfix = a1_affix[a1_affix.index(')')+1:-1]\n",
    "    if a1_prefix not in b1_lex or a1_postfix not in b1_lex:\n",
    "        return '??'\n",
    "    b1_stem = b1_lex.replace('^', '').replace('$', '').replace(a1_prefix, '', 1)\n",
    "    if a1_postfix:  # if not empty\n",
    "        b1_stem = ''.join(b1_stem.rsplit(a1_postfix, 1))\n",
    "    b2_lex = a2_affix.replace('(.+)', b1_stem)\n",
    "    return b2_lex.replace('^', '').replace('$', '') + '_' + a2_cat\n",
    "\n",
    "def edge_compare(e1, e2):\n",
    "    return e1['label'].split('$')[0] == e2['label'].split('$')[0]\n",
    "\n",
    "def completion(G_candidate, G_model):\n",
    "    GM = isomorphism.DiGraphMatcher(G_model, G_candidate, node_match=lambda v1,v2: v1['label'] == v2['label'], edge_match=edge_compare)\n",
    "    node_diff = set()\n",
    "    matching_count = 0\n",
    "    for subgraph in GM.subgraph_isomorphisms_iter():\n",
    "        node_diff = G_model.nodes - subgraph\n",
    "    subgraph_keys = list(subgraph.keys())\n",
    "    equivalence = dict()\n",
    "    score = 0  # sum of frequencies\n",
    "    for d in node_diff:\n",
    "        equivalence[d] = generate_lexeme(subgraph_keys[0], d, subgraph.get(subgraph_keys[0]))\n",
    "        score_d = get_frequency(equivalence[d])\n",
    "        score += score_d\n",
    "        if score_d == 0 and equivalence[d].split('_')[0] not in demonette_lexemes:\n",
    "            score -= 1\n",
    "    return (subgraph, equivalence, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f067e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_graph(ori_dict, pred_dict, candidate_number, model_number):\n",
    "    dot_filenames = glob.glob(join('demonette-glawinette_graph', model_number + '*'))\n",
    "    if not dot_filenames: # dot file not found\n",
    "        return\n",
    "    dot_filename = dot_filenames[0]\n",
    "    f_out = codecs.open(join('predictions', candidate_number + ' + ' + model_number + '.dot'), 'w+', encoding='latin-1')\n",
    "    with codecs.open(dot_filename, 'r', encoding='latin-1') as f:\n",
    "        for line in f:\n",
    "            if '{' in line or '}' in line:  # first and last line\n",
    "                f_out.write(line)\n",
    "            elif '->' in line:\n",
    "                elements = line.split()\n",
    "                line = re.sub(r'G: [A-zÃ€-Ãº-]*', '', line)\n",
    "                line = re.sub(r'label=\"[A-z]*: ', 'label=\"', line)\n",
    "                if elements[0].replace('\"', '') in pred_dict or elements[2].replace('\"', '') in pred_dict:\n",
    "                    line = re.sub(r'\\];', ', color=blue, fontcolor=blue];', line)\n",
    "                f_out.write(line)\n",
    "            else:\n",
    "                elements = line.split()\n",
    "                lexeme_cat = elements[0].replace('\"', '')\n",
    "                if lexeme_cat in ori_dict:\n",
    "                    pred = ori_dict.get(lexeme_cat)\n",
    "                    line = line.replace('label=\"' + lexeme_cat.split('_')[0], 'label=\"' + pred.split('_')[0])\n",
    "                    line = line.replace('\"]', ', ' + str(get_frequency(pred)) + '\"]')\n",
    "                else:\n",
    "                    pred = pred_dict.get(lexeme_cat)\n",
    "                    line = line.replace('label=\"' + lexeme_cat.split('_')[0], 'label=\"' + pred.split('_')[0])\n",
    "                    line = line.replace('];', ', color=blue, fontcolor=blue];')\n",
    "                    if pred != '??':\n",
    "                        line = line.replace('\", color', ', ' + str(get_frequency(pred)) + '\", color')\n",
    "                f_out.write(line)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22d185",
   "metadata": {},
   "source": [
    "# generate predictions for one family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee93993",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dir = 'demonette-glawinette_graph_binary'\n",
    "candidate_number = 'F06606-01'\n",
    "model_group_number = 'F01896'\n",
    "candidate = pickle.load(open(join(binary_dir, candidate_number), 'rb'))\n",
    "families = glob.glob(join(binary_dir, model_group_number + '*'))\n",
    "max_score = -1\n",
    "subgraph = dict()\n",
    "equivalence = dict()\n",
    "chosen_model_number = model_group_number\n",
    "for family in families:\n",
    "    model = pickle.load(open(family, 'rb'))\n",
    "    new_subgraph, new_equivalence, score = completion(candidate, model)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        subgraph = new_subgraph\n",
    "        equivalence = new_equivalence\n",
    "        chosen_model_number = family.split('\\\\')[1]\n",
    "#print(subgraph)\n",
    "#print(equivalence)\n",
    "generate_prediction_graph(subgraph, equivalence, candidate_number, chosen_model_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b5e29",
   "metadata": {},
   "source": [
    "# automatic for all concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19c4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored = ['F06082', 'F06086', 'F06138', 'F04553', 'F04843', 'F04879', 'F04942', 'F04945', 'F05607', 'F05702', 'F05920', 'F05956', 'F05989', 'F05963', 'F06003', 'F06020', 'F06027', 'F06030', 'F06032', 'F06038', 'F06048', 'F06049', 'F06050', 'F06067', 'F06072', 'F06085', 'F06102', 'F06127', 'F06129', 'F06139', 'F06165', 'F06167', 'F06168', 'F06188', 'F06192', 'F06197']\n",
    "graph_filenames = list()\n",
    "graph_binary_filenames = list()\n",
    "for f in listdir('demonette-glawinette_graph'):\n",
    "    if isfile(join('demonette-glawinette_graph', f)):\n",
    "        if f.split()[0] not in ignored:\n",
    "            graph_filenames.append(f)\n",
    "for f in listdir('demonette-glawinette_graph_binary'):\n",
    "    if isfile(join('demonette-glawinette_graph_binary', f)):\n",
    "        if f not in ignored:\n",
    "            graph_binary_filenames.append(f)\n",
    "graph_filenames.sort()\n",
    "graph_binary_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38929a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = nx.DiGraph()\n",
    "with codecs.open(join('demonette-glawinette_posets', 'maxgraph_simplified.dot'), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if '->' in line:\n",
    "            v = line.split()\n",
    "            L.add_edge(v[2], v[0])\n",
    "        elif 'Attribute' in line:\n",
    "            vertex_id = line.split()[0]\n",
    "            #introduced_intent = col_names[int(line.split('|')[1].replace('Attribute ', '').replace('\\\\n', ''))]\n",
    "            introduced_extent = line.replace('Object ', '').split('|')[-1].split('\\\\n')[:-1]\n",
    "            extent_size = re.search('E: (.*)\\)', line).group(1)\n",
    "            introduced_extent = list(map(lambda e: graph_binary_filenames[int(e)], introduced_extent))\n",
    "            L.add_node(vertex_id, introduced_intent=int(line.split('|')[1].replace('Attribute ', '').replace('\\\\n', '')),\\\n",
    "                       extent_size=extent_size, introduced_extent=introduced_extent,\\\n",
    "                       concept_number=re.search('<(.*)>', line).group(1))\n",
    "vertices = list(L.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ce6093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduced_intent': 6717,\n",
       " 'extent_size': '125',\n",
       " 'introduced_extent': ['F06606-0', 'F06606-1'],\n",
       " 'concept_number': '6786'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.nodes['1628289406']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c8ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F03705 -2\n",
      "F01918 -3\n",
      "F03502 -2\n",
      "F00477 -3\n",
      "F01247 -3\n",
      "F00994 17\n",
      "F01854 0\n",
      "F02475 -3\n",
      "F00303 1\n",
      "F03188 -3\n",
      "F01504 -4\n",
      "F00779 -17\n",
      "F00414 -22\n",
      "F00100 -23\n",
      "F00671 -50\n",
      "F00576 11568\n",
      "F01899 15\n",
      "F02428 16\n",
      "F00804 4\n",
      "F01047 2\n",
      "F00162 -4\n",
      "F00299 2\n",
      "F03083 -7\n",
      "F02231 -4\n",
      "F03445 0\n",
      "F03571 -17\n",
      "F01366 1\n",
      "F02952 -4\n",
      "F02474 -4\n",
      "F03924 -5\n",
      "F01651 -17\n",
      "F00387 -15\n",
      "F01667 10\n",
      "F00771 4\n",
      "F01319 -8\n",
      "F00331 -7\n",
      "F00505 -5\n",
      "F00748 0\n",
      "F00444 -3\n",
      "F01275 -30\n",
      "F01934 -6\n",
      "F00510 -37\n",
      "F01532 -13\n",
      "F00522 -13\n",
      "F01286 0\n",
      "F00179 2\n",
      "F02782 -19\n",
      "F01390 -5\n",
      "F01100 -7\n",
      "F01776 -6\n",
      "F01701 0\n",
      "F02090 1\n",
      "F00885 5\n",
      "F02632 -33\n",
      "F01998 -15\n",
      "F00174 -23\n",
      "F00402 -10\n",
      "F02313 -13\n",
      "F00244 -67\n",
      "F00049 17\n",
      "F01475 -23\n",
      "F01838 -21\n",
      "F02684 -28\n",
      "F01744 -35\n",
      "F01544 0\n",
      "F03844 -9\n",
      "F02823 -24\n",
      "F00684 -20\n",
      "F03668 -19\n",
      "F01610 -1\n",
      "F01901 -2\n",
      "F00620 -26\n",
      "F02648 -10\n",
      "F00648 -7\n",
      "F02010 0\n",
      "F02241 11\n",
      "F00042 -4\n",
      "F01822 7\n",
      "F00177 -4\n",
      "F00306 -30\n",
      "F00407 -15\n",
      "F00880 11585\n",
      "F00796 -9\n",
      "F01223 9\n",
      "F01391 7\n",
      "F02392 -7\n",
      "F00791 -4\n",
      "F01311 -25\n",
      "F01355 -15\n",
      "F03019 -11\n",
      "F01964 11608\n",
      "F00021 -9\n",
      "F01896 -4\n",
      "F00999 8\n",
      "F00292 0\n",
      "F03705 1\n",
      "F01918 10\n",
      "F03502 8\n",
      "F00477 -3\n",
      "F01247 5\n",
      "F00994 3\n",
      "F01854 0\n",
      "F02475 9\n",
      "F00303 -8\n",
      "F03188 -2\n",
      "F01504 -14\n",
      "F00779 -16\n",
      "F00414 -30\n",
      "F00100 -29\n",
      "F00671 -39\n",
      "F00576 -16\n",
      "F01899 -3\n",
      "F02428 8\n",
      "F00804 9\n",
      "F01047 8\n",
      "F00162 -5\n",
      "F00299 9\n",
      "F03083 7\n",
      "F02231 9\n",
      "F03445 9\n",
      "F03571 -17\n",
      "F01366 8\n",
      "F02952 -4\n",
      "F02474 7\n",
      "F03924 8\n",
      "F01651 -18\n",
      "F00387 -14\n",
      "F01667 0\n",
      "F00771 4\n",
      "F01319 -7\n",
      "F00331 -10\n",
      "F00505 -8\n",
      "F00748 8\n",
      "F00444 0\n",
      "F01275 -16\n",
      "F01934 -10\n",
      "F00510 -24\n",
      "F01532 -10\n",
      "F00522 -13\n",
      "F01286 9\n",
      "F00179 -1\n",
      "F02782 -8\n",
      "F01390 -9\n",
      "F01100 7\n",
      "F01776 5\n",
      "F01701 7\n",
      "F02090 8\n",
      "F00885 10\n",
      "F02632 -22\n",
      "F01998 -10\n",
      "F00174 -20\n",
      "F00402 0\n",
      "F02313 1\n",
      "F00244 -67\n",
      "F00049 -9\n",
      "F01475 -12\n",
      "F01838 -18\n",
      "F02684 -18\n",
      "F01744 -23\n",
      "F01544 9\n",
      "F03844 5\n",
      "F02823 -35\n",
      "F00684 -3\n",
      "F03668 -19\n",
      "F01610 -4\n",
      "F01901 -16\n",
      "F00620 -22\n",
      "F02648 3\n",
      "F00648 -4\n",
      "F02010 7\n",
      "F02241 2\n",
      "F00042 9\n",
      "F01822 -8\n",
      "F00177 7\n",
      "F00306 -23\n",
      "F00407 -12\n",
      "F00880 -3\n",
      "F00796 4\n",
      "F01223 0\n",
      "F01391 5\n",
      "F02392 3\n",
      "F00791 3\n",
      "F01311 -37\n",
      "F01355 -12\n",
      "F03019 2\n",
      "F01964 -3\n",
      "F00021 -1\n",
      "F01896 6\n",
      "F00999 7\n",
      "F00292 7\n"
     ]
    }
   ],
   "source": [
    "binary_dir = 'demonette-glawinette_graph_binary'\n",
    "for v in vertices:\n",
    "    if v != '1628289406':\n",
    "        continue\n",
    "    descendants = nx.descendants(L, v)\n",
    "    for candidate_number in L.nodes[v]['introduced_extent']:\n",
    "        candidate = pickle.load(open(join(binary_dir, candidate_number), 'rb'))\n",
    "        max_score = -1000\n",
    "        subgraph = dict()\n",
    "        equivalence = dict()\n",
    "        for d in descendants:\n",
    "            if len(list(L.neighbors(d))) > 0:  # not leaf\n",
    "                continue\n",
    "            model_group_numbers = L.nodes[d]['introduced_extent']\n",
    "            for family in model_group_numbers:\n",
    "                model = pickle.load(open(join(binary_dir, family), 'rb'))\n",
    "                new_subgraph, new_equivalence, score = completion(candidate, model)\n",
    "                print(family, score)\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    subgraph = new_subgraph\n",
    "                    equivalence = new_equivalence\n",
    "                    chosen_model_number = family\n",
    "        generate_prediction_graph(subgraph, equivalence, candidate_number, chosen_model_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b6fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
