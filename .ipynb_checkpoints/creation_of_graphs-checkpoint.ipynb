{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = pickle.load(open('G.p', 'rb'))\n",
    "lexeme_dict = pickle.load(open('lexeme_dict.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for all families, directed, cstr in edges\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    edge_type = line_elements[19] + '_' + line_elements[14] + '-' + line_elements[17]\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    edge_type = line_elements[19] + '_' + line_elements[17] + '-' + line_elements[14]\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "                else:\n",
    "                    sorted_cstr = sorted([line_elements[14], line_elements[17]])\n",
    "                    edge_type = line_elements[21] + '_' + line_elements[19] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    write_dot(H, join('graphs_directed', input_file.replace('.txt','.dot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nf', 'V', 'Nm', 'Adj', 'Nmp', 'Nx', 'Npx', 'Nfp', 'Npmp', 'Adv', 'Num']\n",
      "['simple_X-X', 'simple_X-Xment', 'indirect_simple_Xeur-Xment', 'simple_X-Xeur', 'NA_simple_X-X', 'indirect_simple_Xeuse-Xment', 'simple_X-Xeuse', 'indirect_simple_Xeur-Xeuse', 'simple_X-Xique', 'simple_X-Xataire', 'simple_X-Xage', 'indirect_simple_Xage-Xment', 'indirect_simple_Xage-Xeuse', 'simple_X-Xure', 'simple_X-Xion', 'indirect_simple_Xage-Xeur', 'simple_X-Xaie', 'simple_X-Xier', 'simple_X-Xière', 'indirect_simple_Xeur-Xif', 'indirect_simple_Xeur-Xion', 'indirect_simple_Xeur-Xrice', 'indirect_simple_Xif-Xion', 'simple_X-Xif', 'indirect_simple_Xif-Xrice', 'indirect_simple_Xion-Xrice', 'simple_X-Xrice', 'simple_X-Xade', 'simple_X-Xerie', 'indirect_complexe_X-Xion', 'indirect_simple_Xeur-Xeur', 'simple_X-Xal', 'simple_X-Xaire', 'simple_X-Xance', 'simple_X-Xence', 'simple_X-Xer', 'motiv-sem_X-subXaire', 'simple_X-Xiser', 'indirect_simple_Xaire-Xation', 'simple_X-Xée', 'indirect_motiv-sem_Xal-Xion', 'indirect_motiv-sem_Xique-Xiste', 'motiv-sem_X-quadriXaire', 'motiv-sem_X-quinquXaire', 'indirect_motiv-sem_Xage-Xal', 'simple_X -Xaie', 'simple_X -Xée', 'simple_X-Xère', 'motiv-sem_X-Xural', 'motiv-sem_X-Xistique', 'simple_X-Xistique', 'indirect_simple_Xion-Xment', 'indirect_simple_Xeuse-Xion', 'indirect_motiv-sem_Xal-Xie', 'indirect_simple_X-Xeur', 'indirect_simple_Xaire-Xion', 'simple_X-enX', 'simple_X-Xaison', 'indirect_simple_Xage-Xière', 'motiv-sem_X-Xique', 'complexe_X-Xonnière', 'complexe_X-Xetier', 'NA_motiv-sem_X-X', 'simple_X-Xette', 'accidentel_X-enX', 'simple_X-Xis', 'motiv-sem_X-extraXaire', 'indirect_simple_Xage-Xion', 'indirect_simple_X-Xise', 'indirect_simple_Xeuse-Xrice', 'simple_X-Xing', 'indirect_simple_X-Xière', 'simple_X-Xoine', 'simple_X -Xeraie', 'indirect_simple_X-Xier', 'motiv-sem_X-biXaire', 'motiv-sem_X-triXaire', 'motiv-sem_X-uniXaire', 'indirect_motiv-sem_Xeur-Xique', 'indirect_simple_Xeur-Xure', 'indirect_motiv-sem_Xoral-Xure', 'indirect_simple_X-Xerie', 'simple_X-Xeraie', 'simple_X-Xois', 'indirect_motiv-sem_Xitique-Xois', 'indirect_simple_Xie-Xier', 'motiv-sem_X-infraXaire', 'motiv-sem_X-supraXaire', 'NA_accidentel_X-Xoire', 'simple_X-Xant', 'indirect_motiv-sem_Xal-Xant', 'motiv-form_X-Xiser', 'motiv-sem_X-Xaliser', 'simple_X-Xable', 'motiv-sem_X-antiXaire', 'indirect_simple_Xaie-Xier', 'indirect_simple_Xier-Xine', 'simple_X-Xise', 'simple_X-aX', 'NA_accidentel_X-X', 'complexe_X-Xionnaire', 'motiv-sem_X-interXaire', 'simple_X-Xaille', 'motiv-sem_X-multiXaire', 'motiv-sem_X-pluriXaire', 'motiv-sem_X-sexXaire', 'indirect_simple_X-Xrice', 'indirect_motiv-sem_Xion-Xoral', 'motiv-sem_X-intraXaire', 'indirect_simple_Xeuse-Xif', 'indirect_simple_Xeur-Xise', 'indirect_motiv-sem_Xise-Xoral', 'motiv-sem_X-preXière', 'complexe_X-Xaire', 'indirect_motiv-sem_Xal-Xise', 'complexe_X-Xonnier', 'simple_X-Xel', 'simple_X-métaX', 'indirect_simple_Xage-Xier', 'complexe_X-Xilier', 'simple_X-Xie', 'indirect_motiv-sem_X-X', 'motiv-sem_X-postXaire', 'motiv-sem_X-préXaire', 'motiv-sem_X-Xulaire', 'simple_X-Xule', 'simple_Xage-X', 'complexe_X-Xetière', 'indirect_motiv-sem_Xique-Xisme', 'motiv-sem_X-juxtaXaire', 'motiv-sem_X-matriXaire', 'motiv-sem_X-patriXaire', 'motiv-sem_X-coXier', 'simple_X-Xange', 'motiv-sem_X-circumXaire', 'simple_X-Xat', 'indirect_motiv-sem_Xal-Xat', 'motiv-sem_X-aXaire', 'motiv-sem_X-circomXaire', 'motiv-sem_X-monoXaire', 'motiv-sem_X-omniXaire', 'motiv-sem_X-périXaire', 'motiv-sem_X-tétraXaire', 'motiv-sem_X-transXaire', 'NA _simple_X-X', 'NA_accidentel_X-Xion', 'indirect_complexe_Xerie-Xiser', 'complexe_X-Xise', 'motiv-sem_X-diXaire', 'motiv-sem_X-polyXaire', 'indirect_complexe_X-Xage', 'NA_accidentel_X-Xande', 'indirect_simple_Xier-Xée', 'motiv-sem_X-sousXaire', 'motiv-form_X-Xistique', 'indirect_motiv-sem_Xisme-Xistique', 'simple_X-Xon', 'simple_X-Xoyer', 'simple_X-Xassier', 'simple_X-Xisme', 'simple_X-Xiste', 'indirect_simple_Xat-Xé', 'simple_X-Xé', 'indirect_motiv-sem_Xal-Xé', 'indirect_motiv-sem_Xoire-Xoral', 'indirect_motiv-sem_Xique-Xment', 'motiv-sem_X-Xétique', 'motiv-sem_X-nasoXier', 'indirect_complexe_X-Xisme', 'indirect_simple_X-Xaire', 'simple_X-inX', 'motiv-sem_X-aquaXaire', 'simple_X-Xien', 'motiv-sem_X-Xoral', 'simple_X-Xatiser', 'simple_X-Xatique', 'indirect_motiv-sem_Xaire-Xion', 'indirect_simple_Xerie-Xiser', 'simple_X-biX', 'complexe_X-Xagier', 'indirect_simple_Xiser-Xisme', 'NA_accidentel_X-Xaire', 'indirect_simple_Xion-Xé', 'simple_X-Xet', 'indirect_simple_Xeur-Xoire', 'indirect_simple_Xment-Xrice', 'complexe_X-Xassier', 'indirect_motiv-sem_Xique-Xité', 'NA_accidentel_X-Xeur', 'NA_accidentel_X-Xice', 'NA_accidentel_X-Xif', 'simple_X-Xais', 'indirect_motiv-sem_Xeur-Xistique', 'indirect_motiv-sem_Xeuse-Xistique', 'simple_X-Xité', 'simple_X-Xical', 'indirect_simple_X-Xité', 'simple_X-autoX', 'motiv-form_X-inX', 'motiv-sem_X-inXiser', 'simple_X-Xaliser', 'motiv-sem_X-interXal', 'motiv-form_X-interX', 'indirect_simple_Xisme-Xiste', 'complexe_X-Xisme', 'simple_X-sousX', 'indirect_simple_Xage-Xrice', 'indirect_simple_X-Xeuse', 'indirect_simple_Xion-Xion', 'indirect_simple_Xage-Xonner', 'accidentel_X-Xment', 'indirect_motiv-sem_Xien-Xique', 'indirect_simple_Xique-Xisme', 'motiv-sem_X-sousXier', 'motiv-sem_X-hypoXaire', 'motiv-sem_X-équiXaire', 'motiv-sem_X-orthoXaire', 'motiv-sem_X-coXaire', 'indirect_simple_Xisme-Xité', 'indirect_simple_Xiste-Xité', 'indirect_motiv-sem_Xistique-Xité', 'motiv-sem_X-exXaire', 'indirect_simple_Xie-Xé', 'simple_X-Xeté', 'indirect_simple_Xal-Xeté', 'indirect_motiv-sem_Xal-Xien', 'simple_X-Xaume', 'indirect_motiv-sem_Xal-Xaume', 'simple_X-Xoïde', 'motiv-sem_X-Xoïdal', 'simple_X -Xal', 'motiv-sem_X-sousXière', 'motiv-sem_X-transXalier', 'indirect_motiv-sem_Xat-Xique', 'indirect_motiv-sem_Xique-Xétique', 'indirect_motiv-sem_Xgenèse-Xgénique', 'simple_X-Xeute', 'indirect_motiv-sem_Xeutique-Xique', 'motiv-sem_X-Xeutique', 'indirect_motiv-sem_Xeute-Xique', 'indirect_motiv-sem_X-Xique', 'indirect_motiv-sem_Xant-Xique', 'indirect_motiv-sem_Xique-Xite', 'simple_X-Xeux', 'indirect_motiv-sem_Xeux-Xique', 'indirect_motiv-sem_Xerie-Xique', 'simple_X -Xraie', 'indirect_simple_Xier-Xraie', 'complexe_X-Xailler', 'complexe_X-Xinière', 'motiv-sem_X-quartXier', 'motiv-sem_X-superXaire', 'simple_X-Xairie', 'motiv-sem_X-ultraXaire', 'motiv-sem_X-inXaire', 'motiv-sem_X-podoXaire', 'simple_X-Xailler', 'motiv-sem_X-bioXaire', 'motiv-sem_X-centroXaire', 'motiv-sem_X-proXaire', 'motiv-sem_X-trichoXaire']\n"
     ]
    }
   ],
   "source": [
    "# toggle1: create directed graph for gSpan input, cstr in edges\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0].replace('F', '')\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                \n",
    "                vertex_a_type = line_elements[8]\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                vertex_b_type = line_elements[10]\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(line_elements[3] + '_' + line_elements[8], label=vertex_a_label)\n",
    "                H.add_node(line_elements[6] + '_' + line_elements[10], label=vertex_b_label)\n",
    "                    \n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des':\n",
    "                    edge_type = line_elements[19] + '_' + line_elements[14] + '-' + line_elements[17] \n",
    "                elif orientation == 'de2as' or orientation == 'des2as':\n",
    "                    edge_type = line_elements[19] + '_' + line_elements[17] + '-' + line_elements[14] \n",
    "                else:  # NA or indirect\n",
    "                    sorted_cstr = sorted([line_elements[14], line_elements[17]])\n",
    "                    edge_type = orientation + '_' + line_elements[19] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if orientation == 'as2de' or orientation == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                elif orientation == 'de2as' or orientation == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "            #print('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']))\n",
    "f_out.close()\n",
    "print(vertex_labels)\n",
    "print(edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for all families, directed, no cstr in edges\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    write_dot(H, join('graphs_directed', input_file.replace('.txt','.dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: create directed graph for gSpan input, cstr in vertices\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0].replace('F', '')\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                \n",
    "                vertex_a_type = line_elements[8] + '_' + line_elements[14]\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                vertex_b_type = line_elements[10] + '_' + line_elements[17]\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(line_elements[3] + '_' + line_elements[8], label=vertex_a_label)\n",
    "                H.add_node(line_elements[6] + '_' + line_elements[10], label=vertex_b_label)\n",
    "                    \n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "f_out.close()\n",
    "print(vertex_labels)\n",
    "print(edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vertex_label_file = open('label_vertex.p', 'wb')\n",
    "pickle.dump(vertex_labels, vertex_label_file)\n",
    "vertex_label_file.close()\n",
    "\n",
    "edge_label_file = open('label_edge.p', 'wb')\n",
    "pickle.dump(edge_labels, edge_label_file)\n",
    "edge_label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for one family\n",
    "input_lexeme = 'effilocher'\n",
    "\n",
    "family_file = lexeme_dict[input_lexeme]\n",
    "H = nx.MultiGraph()\n",
    "with codecs.open(join('families', family_file), 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num >= 2:\n",
    "            line_elements = line.replace('\\n','').split('\\t')\n",
    "            H.add_edge(line_elements[3], line_elements[6], origin = line_elements[12])\n",
    "write_dot(H, 'graphs/' + family_file.replace('.txt','.dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for all families\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    H = nx.Graph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                #H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], origin = line_elements[12])\n",
    "                H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10])\n",
    "    write_dot(H, 'graphs/' + input_file.replace('.txt','.dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# toggle1: using manual file writing to .dot, for one family\n",
    "input_lexeme = 'effilocher'\n",
    "\n",
    "family_file = lexeme_dict[input_lexeme]\n",
    "H = nx.MultiGraph()\n",
    "f_out = codecs.open(join('graphs', family_file.replace('.txt','.dot')), 'w+', encoding='utf-8')\n",
    "f_out.write('graph G{\\n')\n",
    "with codecs.open(join('families', family_file), 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num >= 2:\n",
    "            line_elements = line.replace('\\n','').split('\\t')\n",
    "            f_out.write('\\\"' + line_elements[3] + '\\\"--\\\"' + line_elements[6] + '\\\"\\n')\n",
    "f_out.write('}\\n')\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
