{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:124: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import printProgressBar\n",
    "\n",
    "# column number\n",
    "graph_1 = 3\n",
    "graph_2 = 6\n",
    "cat_1 = 8\n",
    "cat_2 = 10\n",
    "cstr_1 = 14\n",
    "cstr_2 = 17\n",
    "complexite = 19\n",
    "orientation = 21\n",
    "fichier_origine = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all valid cstr (Xeur, Xette, reX, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "family_name_dict = dict()\n",
    "valid_cstr = set()\n",
    "valid_cstr.add('X')\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        family_name_dict[input_file.split()[0]] = input_file.split()[1].split('.')[0]  # for setting hyperlink in excel\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('Nm', 'N').replace('Nf', 'N)'.replace(' ', '').split('\\t')\n",
    "                construction1 = elements[cstr_1].replace('1', '').replace('2', '')\n",
    "                construction2 = elements[cstr_2].replace('1', '').replace('2', '')\n",
    "                if construction1 == 'X' and construction2 == 'X':\n",
    "                    continue\n",
    "                if construction1 == 'X':\n",
    "                    valid_cstr.add(construction2 + '-' + elements[cat_1] + '-' + elements[cat_2])\n",
    "                valid_cstr.add(construction1)\n",
    "                valid_cstr.add(construction2)\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(input_files), prefix='Progress:', suffix='complete', length=50, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Xable', 'Xade', 'Xage', 'Xagier', 'Xaie', 'Xaille', 'Xailler', 'Xaillette', 'Xainat', 'Xaire', 'Xairie', 'Xais', 'Xaison', 'Xal', 'Xalat', 'Xalette', 'Xaliser', 'Xanat', 'Xance', 'Xande', 'Xange', 'Xant', 'Xariat', 'Xariser', 'Xassier', 'Xat', 'Xataire', 'Xate', 'Xaticat', 'Xation', 'Xatique', 'Xaume', 'Xel', 'Xelat', 'Xelet', 'Xelette', 'Xellette', 'Xence', 'Xenet', 'Xent', 'Xer', 'Xeraie', 'Xeret', 'Xerette', 'Xerie', 'Xerète', 'Xet', 'Xetier', 'Xetière', 'Xette', 'Xettes', 'Xeté', 'Xeur', 'Xeuse', 'Xeute', 'Xeutique', 'Xeux', 'Xfère', 'Xgenèse', 'Xgénique', 'Xiat', 'Xiau', 'Xicat', 'Xice', 'Xichette', 'Xiculet', 'Xie', 'Xien', 'Xier', 'Xiette', 'Xif', 'Xifier', 'Xikat', 'Xilier', 'Xillette', 'Xinat', 'Xine', 'Xinet', 'Xinette', 'Xinettes', 'Xing', 'Xinière', 'Xion', 'Xionat', 'Xionnaire', 'Xique', 'Xiquet', 'Xiquette', 'Xis', 'Xise', 'Xiser', 'Xisme', 'Xissariat', 'Xiste', 'Xistique', 'Xite', 'Xitique', 'Xité', 'Xium', 'Xière', 'Xlet', 'Xlette', 'Xlogie', 'Xlogique', 'Xment', 'Xoine', 'Xoire', 'Xois', 'Xolat', 'Xolet', 'Xon', 'Xonet', 'Xonette', 'Xonner', 'Xonnet', 'Xonnette', 'Xonnier', 'Xonnière', 'Xoral', 'Xorat', 'Xoriat', 'Xot', 'Xoter', 'Xouette', 'Xouillet', 'Xouillette', 'Xoulet', 'Xounet', 'Xounette', 'Xouquette', 'Xoyer', 'Xoïdal', 'Xoïde', 'Xraie', 'Xrette', 'Xrice', 'Xulaire', 'Xulat', 'Xule', 'Xural', 'Xure', 'Xus', 'Xère', 'Xète', 'Xètes', 'Xé', 'Xéat', 'Xée', 'Xérat', 'Xériat', 'Xétique', 'aX', 'aXaire', 'antiXaire', 'aquaXaire', 'autoX', 'biXaire', 'biXet', 'bioX', 'bioXaire', 'centroXaire', 'circomXaire', 'circumXaire', 'coX', 'coXaire', 'coXier', 'contreX', 'diXaire', 'disX', 'déX', 'déXaliser', 'déXifier', 'déXiner', 'déXiser', 'enX', 'exXaire', 'extraXaire', 'hyperX', 'hypoX', 'hypoXaire', 'inX', 'inXaire', 'infraXaire', 'interX', 'interXaire', 'intraXaire', 'juxtaXaire', 'matriXaire', 'monoXaire', 'multiXaire', 'nasoXier', 'nonX', 'omniXaire', 'orthoXaire', 'paraX', 'patriXaire', 'pluriXaire', 'podoXaire', 'polyX', 'polyXaire', 'postXaire', 'preXière', 'proXaire', 'protoXicat', 'préX', 'préXaire', 'périXaire', 'quadriXaire', 'quartXier', 'quinquXaire', 'rX', 'reX', 'réX', 'semiX', 'sexXaire', 'sousX', 'sousXaire', 'sousXier', 'sousXière', 'subXaire', 'superXaire', 'supraXaire', 'surX', 'synX', 'thermoX', 'transX', 'transXaire', 'transXalier', 'triXaire', 'trichoXaire', 'tétraXaire', 'ultraXaire', 'uniXaire', 'viceX', 'vraiX', 'éX', 'éXette', 'équiX', 'équiXaire']\n"
     ]
    }
   ],
   "source": [
    "valid_cstr.update(['rX', 'réX'])\n",
    "print(sorted(list(valid_cstr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all lexemes in each family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13178\n"
     ]
    }
   ],
   "source": [
    "family_dict = dict()\n",
    "with codecs.open('summary_of_families.txt', 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num == 0:\n",
    "            continue\n",
    "        cols = line.split('\\t')\n",
    "        lexemes = cols[2].replace('{','').replace('}','').replace('\\'','').replace('\\n','').split(', ')\n",
    "        family_dict[cols[0]] = set(lexemes)\n",
    "print(len(family_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# section to obtain families that contain two given families\n",
    "L = nx.DiGraph()\n",
    "vertex_attribute_dict = dict()\n",
    "with codecs.open(join('posets', 'families_simplified_maxgraph.dot'), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if '->' in line:  # a line showing edges between concepts\n",
    "            elements = line.split()\n",
    "            L.add_edge(vertex_attribute_dict[elements[2]], vertex_attribute_dict[elements[0]])\n",
    "        elif 'shape' in line:  # a line describing a concept \n",
    "            attribute_number = re.search('Attribute (.*)\\|', line.replace('\\\\n', '')).group(1)\n",
    "            vertex_attribute_dict[line.split()[0]] = attribute_number\n",
    "            L.add_node(attribute_number)\n",
    "\n",
    "def common_superfamily(family_number_1, family_number_2):\n",
    "    group_1 = str(int(family_number_1.split('-')[0].replace('F', '')))\n",
    "    group_2 = str(int(family_number_2.split('-')[0].replace('F', '')))\n",
    "    if group_1 == group_2:\n",
    "        return 'same family group'\n",
    "    children1 = nx.descendants(L, group_1)\n",
    "    children2 = nx.descendants(L, group_2)\n",
    "    common_children = children1.intersection(children2)\n",
    "    if len(common_children) == 0:\n",
    "        return 'no common superfamily'\n",
    "    if group_1 in children2 or group_2 in children1:\n",
    "        return 'one family is a superfamily of the other'\n",
    "    return_string = ''\n",
    "    for child in common_children:\n",
    "        return_string += 'F' + child.rjust(5, '0') + ' '\n",
    "    return return_string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one family is a superfamily of the other'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_superfamily('F03359-01', 'F03902-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:124: UserWarning: Pandas requires version '0.9.8' or newer of 'xlsxwriter' (version '0.9.6' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# with valid cstr\n",
    "family_dict_keys = list(family_dict.keys())\n",
    "df_valid = pd.DataFrame(columns=['family_id_1', 'family_id_2', 'graph_1', 'cat_1', 'graph_2', 'cat_2', 'cstr_1_presumed', 'cstr_2_presumed', 'superfamilies'])\n",
    "for k1 in range(0, len(family_dict)):\n",
    "    #if family_dict_keys[k1] != 'F01545':\n",
    "        #continue\n",
    "    for k2 in range(k1+1, len(family_dict)):\n",
    "        set1 = family_dict[family_dict_keys[k1]]\n",
    "        set2 = family_dict[family_dict_keys[k2]]\n",
    "        #if family_dict_keys[k2] != 'F03722-5':\n",
    "            #continue\n",
    "        connected = False\n",
    "        for s1 in set1:\n",
    "            [g1, c1] = s1.split('_')\n",
    "            for s2 in set2:\n",
    "                [g2, c2] = s2.split('_')\n",
    "                if g1 in g2 and g2.replace(g1, 'X') in valid_cstr:\n",
    "                    family_id_1 = family_dict_keys[k1]\n",
    "                    family_id_2 = family_dict_keys[k2]\n",
    "                    cstr = g2.replace(g1, 'X')\n",
    "                    graph1 = g1\n",
    "                    graph2 = g2\n",
    "                    cat1 = c1\n",
    "                    cat2 = c2\n",
    "                    connected = True\n",
    "                    break\n",
    "                elif g2 in g1 and g1.replace(g2, 'X') in valid_cstr:\n",
    "                    family_id_1 = family_dict_keys[k2]\n",
    "                    family_id_2 = family_dict_keys[k1]\n",
    "                    cstr = g1.replace(g2, 'X')\n",
    "                    graph1 = g2\n",
    "                    graph2 = g1\n",
    "                    cat1 = c2\n",
    "                    cat2 = c1\n",
    "                    connected = True\n",
    "                    break\n",
    "            if connected:\n",
    "                break\n",
    "        if connected:\n",
    "            df_valid = df_valid.append(pd.Series({\n",
    "                'family_id_1': '=HYPERLINK(\"graph_visualization\\\\' + family_id_1 + ' ' + family_name_dict[family_id_1] + '.dot\", \"' + family_id_1 + '\")',\n",
    "                'family_id_2': '=HYPERLINK(\"graph_visualization\\\\' + family_id_2 + ' ' + family_name_dict[family_id_2] + '.dot\", \"' + family_id_2 + '\")',\n",
    "                'graph_1': graph1,\n",
    "                'graph_2': graph2,\n",
    "                'cat_1': cat1,\n",
    "                'cat_2': cat2,\n",
    "                'cstr_1_presumed': 'X',\n",
    "                'cstr_2_presumed': cstr,\n",
    "                'superfamilies': common_superfamily(family_dict_keys[k1], family_dict_keys[k2])\n",
    "            }), ignore_index=True)\n",
    "    printProgressBar(k1 + 1, len(family_dict), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "df_valid.to_excel('unconnected,_valid_cstr.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# valid + invalid cstr\n",
    "family_dict_keys = list(family_dict.keys())\n",
    "min_ratio = 0.5\n",
    "df_valid_invalid = pd.DataFrame(columns=['family_id_1', 'family_id_2', 'graph_1', 'cat_1', 'cstr_1',\\\n",
    "                                         'graph_2', 'cat_2', 'cstr_2', 'ratio'])\n",
    "for k1 in range(0, len(family_dict)):\n",
    "    for k2 in range(k1+1, len(family_dict)):\n",
    "        set1 = family_dict[family_dict_keys[k1]]\n",
    "        set2 = family_dict[family_dict_keys[k2]]\n",
    "        connected = False\n",
    "        for s1 in set1:\n",
    "            [g1, c1] = s1.split('_')\n",
    "            for s2 in set2:\n",
    "                [g2, c2] = s2.split('_')\n",
    "                if g1 in g2 and len(g1) / len(g2) > min_ratio:\n",
    "                    family_id_1 = family_dict_keys[k1]\n",
    "                    family_id_2 = family_dict_keys[k2]\n",
    "                    cstr = g2.replace(g1, 'X')\n",
    "                    graph1 = g1\n",
    "                    graph2 = g2\n",
    "                    cat1 = c1\n",
    "                    cat2 = c2\n",
    "                    ratio = len(g1) / len(g2)\n",
    "                    connected = True\n",
    "                    break\n",
    "                elif g2 in g1 and len(g2) / len(g1) > min_ratio:\n",
    "                    family_id_1 = family_dict_keys[k2]\n",
    "                    family_id_2 = family_dict_keys[k1]\n",
    "                    cstr = g1.replace(g2, 'X')\n",
    "                    graph1 = g2\n",
    "                    graph2 = g1\n",
    "                    cat1 = c2\n",
    "                    cat2 = c1\n",
    "                    ratio = len(g2) / len(g1)\n",
    "                    connected = True\n",
    "                    break\n",
    "            if connected:\n",
    "                break\n",
    "        if connected:\n",
    "            df_valid_invalid = df_valid_invalid.append(pd.Series({\n",
    "                'family_id_1': family_id_1,\n",
    "                'family_id_2': family_id_2,\n",
    "                'graph_1': graph1,\n",
    "                'graph_2': graph2,\n",
    "                'cat_1': cat1,\n",
    "                'cat_2': cat2,\n",
    "                'cstr_1': 'X',\n",
    "                'cstr_2': cstr,\n",
    "                'ratio': ratio\n",
    "            }), ignore_index=True)\n",
    "    printProgressBar(k1 + 1, len(family_dict), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "df_valid_invalid.to_excel('unconnected.xls', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:124: UserWarning: Pandas requires version '2.6.2' or newer of 'numexpr' (version '2.6.1' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:124: UserWarning: Pandas requires version '0.9.8' or newer of 'xlsxwriter' (version '0.9.6' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# invalid cstr\n",
    "df_valid_invalid = pd.read_excel('unconnected.xls')\n",
    "df_valid = pd.read_excel('unconnected,_valid_cstr.xls')\n",
    "df_valid_invalid['family_id_join'] = df_valid_invalid.apply(lambda row: sorted([row['family_id_1'], row['family_id_2']])[0]\\\n",
    "                                                            + '+' + sorted([row['family_id_1'], row['family_id_2']])[1],\\\n",
    "                                                            axis=1)\n",
    "df_valid['family_id_join'] = df_valid.apply(lambda row: sorted([row['family_id_1'], row['family_id_2']])[0] + '+' + \\\n",
    "                                            sorted([row['family_id_1'], row['family_id_2']])[1], axis=1)\n",
    "df_valid = df_valid[['family_id_join']]\n",
    "df_invalid = df_valid.merge(df_valid_invalid, how = 'outer', on = ['family_id_join'],\\\n",
    "                                              indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "df_invalid.drop(['family_id_join', '_merge'], axis=1, inplace=True)\n",
    "df_invalid.to_excel('unconnected,_invalid_cstr.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin', binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar('approchement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.similarity('boucher', 'déboucher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
