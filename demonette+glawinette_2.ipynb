{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d5f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from networkx.algorithms import isomorphism\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glawinette column number\n",
    "lemma1 = 0\n",
    "lemma2 = 1\n",
    "cat1 = 2\n",
    "cat2 = 3\n",
    "origine_morpho = 4\n",
    "origine_def = 5\n",
    "BAP1 = 6\n",
    "BAP2 = 7\n",
    "BAPsize = 8\n",
    "FAP1 = 9\n",
    "FAP2 = 10\n",
    "FAPsize = 11\n",
    "radical = 12\n",
    "FAPtype = 13\n",
    "\n",
    "# demonette column number\n",
    "graph_1 = 3\n",
    "graph_2 = 6\n",
    "cat_1 = 8\n",
    "cat_2 = 10\n",
    "cstr_1 = 14\n",
    "cstr_2 = 17\n",
    "complexite = 19\n",
    "orientation = 21\n",
    "fichier_origine = 43\n",
    "\n",
    "def FAPconverter(input_fap):\n",
    "    return input_fap.replace('(.+)', 'X').replace('$', '').replace('^', '')\n",
    "\n",
    "def category_shortening(cat):\n",
    "    if cat != 'Num' and cat[0] == 'N':\n",
    "        if cat[1] == 'p':  # nom propre\n",
    "            return 'Np'\n",
    "        return 'N'  # nom\n",
    "    return cat\n",
    "\n",
    "header = ''\n",
    "glawi_dict = dict()\n",
    "with codecs.open('glawinette-series.csv', 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num >= 1:\n",
    "            elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "            glawi_dict[(elements[lemma1], elements[lemma2])] = FAPconverter(elements[FAP1]) + '-' + FAPconverter(elements[FAP2])\n",
    "            glawi_dict[(elements[lemma2], elements[lemma1])] = FAPconverter(elements[FAP2]) + '-' + FAPconverter(elements[FAP1])\n",
    "print(len(glawi_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4102a",
   "metadata": {},
   "source": [
    "# create binary files for graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frcowvec_categories = {'Nm': 'NOM', 'Nf': 'NOM', 'Nmp': 'NOM', 'Nfp': 'NOM', 'Nx': 'NOM', 'More': 'NOM',\n",
    "                       'Npm': 'NAM', 'Npf': 'NAM', 'Npx': 'NAM', 'Npmp': 'NAM', 'Npfp': 'NAM',\n",
    "                       'Adj': 'ADJ', 'V': 'VER', 'Num': 'NUM', 'Pro': 'PRO', 'Adv': 'ADV'}\n",
    "\n",
    "def frcowvec_cat_conversion(lexeme):\n",
    "    old_cat = lexeme.split('_')[-1]\n",
    "    new_cat = frcowvec_categories.get(old_cat)\n",
    "    return lexeme.split('_')[0] + '_' + new_cat\n",
    "\n",
    "frequencies = pd.read_csv('frequencies-frcowvec-filtered.csv', header=0, index_col=0)\n",
    "frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'demonette-glawinette_families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "output_dir = 'demonette-glawinette_graph_binary'\n",
    "\n",
    "for input_file in input_files:\n",
    "    fam_id = input_file.split()[0]\n",
    "    group_id = fam_id.split('-')[0]\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                va = elements[graph_1] + '_' + elements[cat_1]\n",
    "                vb = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(va, vb) or H.has_edge(vb, va):\n",
    "                    continue\n",
    "                try:\n",
    "                    freq_a = frequencies.loc[frcowvec_cat_conversion(va)]['freq']\n",
    "                except KeyError:\n",
    "                    freq_a = 0\n",
    "                try:\n",
    "                    freq_b = frequencies.loc[frcowvec_cat_conversion(vb)]['freq']\n",
    "                except KeyError:\n",
    "                    freq_b = 0\n",
    "                H.add_node(va, label=category_shortening(elements[cat_1]), frequency=freq_a)\n",
    "                H.add_node(vb, label=category_shortening(elements[cat_2]), frequency=freq_b)\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2]\\\n",
    "                                  + '$' + glawi_dict.get((elements[graph_1], elements[graph_2])))\n",
    "                    else:\n",
    "                        H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2])\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    if (elements[graph_2], elements[graph_1]) in glawi_dict.keys():\n",
    "                        H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1]\\\n",
    "                                  + '$' + glawi_dict.get((elements[graph_2], elements[graph_1])))\n",
    "                    else:\n",
    "                        H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1])\n",
    "                else:\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2] + '_' + elements[orientation]\\\n",
    "                                  + '$' + glawi_dict.get((elements[graph_1], elements[graph_2])))\n",
    "                        H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1] + '_' + elements[orientation]\\\n",
    "                                  + '$' + glawi_dict.get((elements[graph_2], elements[graph_1])))\n",
    "                    else:\n",
    "                        H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2] + '_' + elements[orientation])\n",
    "                        H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1] + '_' + elements[orientation])\n",
    "    graph_file = open(join(output_dir, fam_id), 'wb')\n",
    "    pickle.dump(H, graph_file)\n",
    "    graph_file.close()\n",
    "    print(input_file.split()[0], end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5ff92",
   "metadata": {},
   "source": [
    "# creation of formal context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d3c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'demonette-glawinette_graph_binary'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "input_files.sort()\n",
    "node_count_dict = dict()\n",
    "for graph in input_files:\n",
    "    G2 = pickle.load(open(join(input_dir, graph), 'rb'))\n",
    "    node_count_dict[graph] = len(G2)\n",
    "    \n",
    "subgroup_prev = ''\n",
    "context = pd.DataFrame()\n",
    "counter = 1\n",
    "input_files_count = len(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5972d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2933, 168)F00000-105\n"
     ]
    }
   ],
   "source": [
    "def edge_compare(e1, e2):\n",
    "    if '$' in e1['label'] and '$' not in e2['label']:\n",
    "        return e1['label'].split('$')[0] == e2['label']\n",
    "    else:\n",
    "        return e1['label'] == e2['label']\n",
    "\n",
    "for subgraph in input_files:\n",
    "    counter += 1\n",
    "    subgroup_id = subgraph.split('-')[0]\n",
    "    if subgroup_id == subgroup_prev:\n",
    "        continue\n",
    "    membership = [0] * len(input_files)\n",
    "    G2 = pickle.load(open(join(input_dir, subgraph), 'rb'))\n",
    "    G2_node_count = node_count_dict.get(subgraph)\n",
    "    supergroup_prev = ''\n",
    "    is_subgraph = 0\n",
    "    for counter2 in range(input_files_count-1, -1, -1):\n",
    "        if membership[counter2] == 1:\n",
    "            continue\n",
    "        supergraph = input_files[counter2]\n",
    "        supergroup_id = supergraph.split('-')[0]\n",
    "        if supergroup_id == subgroup_id:\n",
    "            membership[counter2] = 1\n",
    "            continue\n",
    "        if supergroup_id == supergroup_prev:\n",
    "            membership[counter2] = membership[counter2+1]\n",
    "            continue\n",
    "        print(subgraph + ' ' + supergraph, end='\\r')\n",
    "        G1_node_count = node_count_dict.get(supergraph)\n",
    "        if G1_node_count > G2_node_count:\n",
    "            G1 = pickle.load(open(join(input_dir, supergraph), 'rb'))\n",
    "            GM = isomorphism.DiGraphMatcher(G1, G2, node_match=lambda v1,v2: v1['label'] == v2['label'], edge_match=edge_compare)\n",
    "            if GM.subgraph_is_isomorphic():\n",
    "                membership[counter2] = 1\n",
    "                try:\n",
    "                    membership_of_G1 = context[supergroup_id.replace('F', 'G')]\n",
    "                    membership = (membership_of_G1 | membership).astype(int)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        supergroup_prev = supergroup_id\n",
    "    subgroup_prev = subgroup_id\n",
    "    membership = pd.Series(membership, name=subgroup_id.replace('F', 'G'))\n",
    "    context = pd.concat([context, membership], axis=1)\n",
    "context.index = input_files\n",
    "print(context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f99d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.to_csv('DG-context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47664c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
