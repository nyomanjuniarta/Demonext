{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from networkx.algorithms import isomorphism\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lexeme(a1, a2, b1):\n",
    "    a1_lex = '^' + a1.split('_')[0] + '$'\n",
    "    a2_lex = '^' + a2.split('_')[0] + '$'\n",
    "    b1_lex = '^' + b1.split('_')[0] + '$'\n",
    "    a2_cat = a2.split('_')[1]\n",
    "    match = SequenceMatcher(None, a1_lex, a2_lex).find_longest_match(0, len(a1_lex), 0, len(a2_lex))\n",
    "    common = a1_lex[match.a:match.a+match.size]\n",
    "    a1_affix = a1_lex.replace(common, '(.+)')\n",
    "    a2_affix = a2_lex.replace(common, '(.+)')\n",
    "    a1_prefix = a1_affix[1:a1_affix.index('(')]\n",
    "    a1_postfix = a1_affix[a1_affix.index(')')+1:-1]\n",
    "    if a1_prefix not in b1_lex or a1_postfix not in b1_lex:\n",
    "        return '??'\n",
    "    b1_stem = b1_lex.replace('^', '').replace('$', '').replace(a1_prefix, '', 1)\n",
    "    if a1_postfix:  # if not empty\n",
    "        b1_stem = ''.join(b1_stem.rsplit(a1_postfix, 1))\n",
    "    b2_lex = a2_affix.replace('(.+)', b1_stem)\n",
    "    return b2_lex.replace('^', '').replace('$', '') + '_' + a2_cat\n",
    "\n",
    "def edge_compare(e1, e2):\n",
    "    return e1['label'].split('$')[0] == e2['label'].split('$')[0]\n",
    "\n",
    "def completion(G_candidate, G_model):\n",
    "    GM = isomorphism.DiGraphMatcher(G_model, G_candidate, node_match=lambda v1,v2: v1['label'] == v2['label'], edge_match=edge_compare)\n",
    "    node_diff = set()\n",
    "    matching_count = 0\n",
    "    for subgraph in GM.subgraph_isomorphisms_iter():\n",
    "        node_diff = G_model.nodes - subgraph\n",
    "    subgraph_keys = list(subgraph.keys())\n",
    "    equivalence = dict()\n",
    "    for d in node_diff:\n",
    "        equivalence[d] = generate_lexeme(subgraph_keys[0], d, subgraph.get(subgraph_keys[0]))\n",
    "    return (subgraph, equivalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f067e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_graph(ori_dict, pred_dict, candidate_number, model_number):\n",
    "    dot_filenames = glob.glob(join('demonette-glawinette_graph', model_number + '*'))\n",
    "    if not dot_filenames: # dot file not found\n",
    "        return\n",
    "    dot_filename = dot_filenames[0]\n",
    "    f_out = codecs.open(join('predictions', candidate_number + ' + ' + model_number + '.dot'), 'w+', encoding='latin-1')\n",
    "    with codecs.open(dot_filename, 'r', encoding='latin-1') as f:\n",
    "        for line in f:\n",
    "            if '{' in line or '}' in line:  # first and last line\n",
    "                f_out.write(line)\n",
    "            elif '->' in line:\n",
    "                elements = line.split()\n",
    "                line = re.sub(r'G: [A-zÀ-ú-]*', '', line)\n",
    "                line = re.sub(r'label=\"[A-z]*: ', 'label=\"', line)\n",
    "                if elements[0].replace('\"', '') in pred_dict or elements[2].replace('\"', '') in pred_dict:\n",
    "                    line = re.sub(r'\\];', ', color=blue, fontcolor=blue];', line)\n",
    "                f_out.write(line)\n",
    "            else:\n",
    "                elements = line.split()\n",
    "                lexeme_cat = elements[0].replace('\"', '')\n",
    "                if lexeme_cat in ori_dict:\n",
    "                    line = line.replace('label=\"' + lexeme_cat.split('_')[0], 'label=\"' + ori_dict.get(lexeme_cat).split('_')[0])\n",
    "                else:\n",
    "                    line = line.replace('label=\"' + lexeme_cat.split('_')[0], 'label=\"' + pred_dict.get(lexeme_cat).split('_')[0])\n",
    "                    line = line.replace('];', ', color=blue, fontcolor=blue];')\n",
    "                f_out.write(line)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee93993",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dir = 'demonette-glawinette_graph_binary'\n",
    "candidate_number = 'F04114'\n",
    "model_number = 'F01426'\n",
    "candidate = pickle.load(open(join(binary_dir, candidate_number), 'rb'))\n",
    "model = pickle.load(open(join(binary_dir, model_number), 'rb'))\n",
    "subgraph, equivalence = completion(candidate, model)\n",
    "#print(subgraph)\n",
    "#print(equivalence)\n",
    "generate_prediction_graph(subgraph, equivalence, candidate_number, model_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc722858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
