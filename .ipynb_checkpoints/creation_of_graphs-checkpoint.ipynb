{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import printProgressBar\n",
    "\n",
    "# column number\n",
    "rid = 0\n",
    "fid = 1\n",
    "lid_1 = 2\n",
    "graph_1 = 3\n",
    "ori_graph_1 = 4\n",
    "lid_2 = 5\n",
    "graph_2 = 6\n",
    "ori_graph_2 = 7\n",
    "cat_1 = 8\n",
    "ori_cat_1 = 9\n",
    "cat_2 = 10\n",
    "ori_cat_2 = 11\n",
    "ori_cple = 12\n",
    "type_cstr_1 = 13\n",
    "cstr_1 = 14\n",
    "ori_cstr_1 = 15\n",
    "type_cstr_2 = 16\n",
    "cstr_2 = 17\n",
    "ori_cstr_2 = 18\n",
    "complexite = 19\n",
    "ori_complexite = 20\n",
    "orientation = 21\n",
    "ori_orientation = 22\n",
    "semty_1 = 23\n",
    "ori_semty_1 = 24\n",
    "semty_2 = 25\n",
    "ori_semty_2 = 26\n",
    "sous_semty_1 = 27\n",
    "sous_semty_2 = 28\n",
    "ori_sous_semty_1 = 29\n",
    "ori_sous_semty_2 = 30\n",
    "semtyrss_1 = 31\n",
    "semtyrss_2 = 32\n",
    "ori_semtyrss_1 = 33\n",
    "ori_semtyrss_2 = 34\n",
    "rel_sem_n1 = 35\n",
    "rel_sem_n2 = 36\n",
    "ori_relsem = 37\n",
    "def_conc = 38\n",
    "ori_def_conc = 39\n",
    "def_abs = 40\n",
    "ori_def_abs = 41\n",
    "commentaires = 42\n",
    "fichier_origine = 43\n",
    "\n",
    "def category_shortening(cat):\n",
    "    if cat != 'Num' and cat[0] == 'N':\n",
    "        return 'N'\n",
    "    return cat\n",
    "\n",
    "def origine(origine_input):\n",
    "    if origine_input == 'CV':\n",
    "        return 'C'\n",
    "    return origine_input\n",
    "\n",
    "frcowvec_categories = {'Nm': 'NOM', 'Nf': 'NOM', 'Nmp': 'NOM', 'Nfp': 'NOM', 'Nx': 'NOM', 'More': 'NOM',\n",
    "                       'Npm': 'NAM', 'Npf': 'NAM', 'Npx': 'NAM', 'Npmp': 'NAM', 'Npfp': 'NAM',\n",
    "                       'Adj': 'ADJ', 'V': 'VER', 'Num': 'NUM', 'Pro': 'PRO', 'Adv': 'ADV'}\n",
    "def frcowvec_cat_conversion(lexeme):\n",
    "    old_cat = lexeme.split('_')[-1]\n",
    "    new_cat = frcowvec_categories.get(old_cat)\n",
    "    return lexeme.split('_')[0] + '_' + new_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_filtered = codecs.open('buffer.csv', 'w+', encoding='utf-8')\n",
    "freq_filtered.write(',freq\\n')\n",
    "with codecs.open('frequencies-frcowvec.csv', 'r', encoding='utf-8') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        if line.count('_') > 1 or line.count(',') > 1:\n",
    "            continue\n",
    "        elements = line.split(',')\n",
    "        [lexeme, category] = elements[0].split('_')\n",
    "        if category in frcowvec_categories.values():\n",
    "            freq_filtered.write(line)\n",
    "        count += 1\n",
    "        print(count, end='\\r')\n",
    "freq_filtered.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772221, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.read_csv('frequencies-frcowvec-filtered.csv', header=0, index_col=0)\n",
    "frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "# toggle1: directed, vertex: lexeme, category. edges: orientation, origin, cstr, --complexite\n",
    "\n",
    "def edge_writer(H):\n",
    "    ret_str = ''\n",
    "    edges = H.edges(data=True)\n",
    "    for e in edges:\n",
    "        cat0 = category_shortening(e[0].split('_')[1])\n",
    "        cat1 = category_shortening(e[1].split('_')[1])\n",
    "            \n",
    "        if H.get_edge_data(*e)['style'] == 'dotted': \n",
    "            ret_str += cat0 + ' -- ' + e[2]['label'].split(': ')[1] + ' -- ' + cat1 + '; '\n",
    "        elif H.get_edge_data(*e)['style'] == 'dashed':\n",
    "            ret_str += cat0 + ' -? ' + e[2]['label'].split(': ')[1] + ' -? ' + cat1 + '; '\n",
    "        else:\n",
    "            ret_str += cat0 + ' -> ' + e[2]['label'].split(': ')[1] + ' -> ' + cat1 + '; '\n",
    "    return ret_str\n",
    "\n",
    "'''def nodes_writer(H):\n",
    "    nodes = H.nodes()\n",
    "    nodes_temp = list()\n",
    "    for node in nodes:\n",
    "        nodes_temp.append(node.split('_')[0])\n",
    "    return str(nodes_temp).replace('\\'', '')'''\n",
    "\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "f_summary = codecs.open('summary_of_family_groups.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('group id\\tnumber of lexemes\\tnumber of pairs\\tpairs\\tnumber of families\\tfamilies\\n')\n",
    "number_of_edges = []\n",
    "number_of_families = []\n",
    "words = ''\n",
    "group_prec = ''\n",
    "family_count = 0\n",
    "H = nx.DiGraph()\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    group_id = input_file.split(' ')[0].split('-')[0]\n",
    "    if group_id != group_prec and group_prec != '':\n",
    "        f_summary.write(group_prec + '\\t' + str(len(H)) + '\\t' + str(H.size()) + '\\t')\n",
    "        #if len(H.edges()) <= 3:\n",
    "        f_summary.write(edge_writer(H)[:-2])\n",
    "        f_summary.write('\\t' + str(family_count) + '\\t' + words[:-2] + '\\n')\n",
    "        number_of_edges.append(H.size())\n",
    "        number_of_families.append(family_count)\n",
    "        family_count = 0\n",
    "        words = ''\n",
    "    family_count += 1\n",
    "    group_prec = input_file.split(' ')[0].split('-')[0]\n",
    "    \n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(v1, v2) or H.has_edge(v2, v1):\n",
    "                    continue\n",
    "                H.add_node(v1, label=elements[graph_1] + '\\n' + category_shortening(elements[cat_1]))\n",
    "                H.add_node(v2, label=elements[graph_2] + '\\n' + category_shortening(elements[cat_2]))\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    H.add_edge(v1, v2, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    H.add_edge(v2, v1, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'indirect':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dotted', label=edge_type)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "                else:\n",
    "                    print(input_file, elements[orientation])\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    words += str(list(H.nodes())) + '; '\n",
    "    write_dot(H, join('temp', input_file.replace('.txt','.dot')))\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(input_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "f_summary.write(group_prec + '\\t' + str(len(H)) + '\\t' + str(H.size()) + '\\t')\n",
    "f_summary.write(edge_writer(H)[:-2])\n",
    "f_summary.write('\\t' + str(family_count) + '\\t' + words[:-2] + '\\n')\n",
    "f_summary.close()\n",
    "number_of_edges.append(H.size())\n",
    "number_of_families.append(family_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "# PNG generation\n",
    "dot_dir = 'temp'\n",
    "dot_files = [f for f in listdir(dot_dir) if isfile(join(dot_dir, f))]\n",
    "counter = 0\n",
    "for dot_file in dot_files:\n",
    "    os.system('dot -Tpng \"' + join(dot_dir, dot_file) + '\" -o \"' + join(dot_dir, dot_file.replace('.dot', '.png')) + '\"')\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(dot_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle1: directed, vertex: lexeme, category. edges: orientation, cstr (FINGERPRINT)\n",
    "\n",
    "def edge_writer(H):\n",
    "    ret_str = ''\n",
    "    edges = H.edges(data=True)\n",
    "    for e in edges:\n",
    "        ret_str += e[2]['label'].split(': ')[1] + '; '\n",
    "    return ret_str[:-2]\n",
    "\n",
    "def nodes_writer(H):\n",
    "    nodes = H.nodes()\n",
    "    nodes_temp = list()\n",
    "    for node in nodes:\n",
    "        nodes_temp.append(node.split('_')[0])\n",
    "    return str(nodes_temp).replace('\\'', '')\n",
    "\n",
    "input_dir = 'families_fingerprint'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "f_summary = codecs.open('summary_of_family_groups_from_fingerprint.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('group id\\tnumber of lexemes\\tnumber of pairs\\tpairs\\tnumber of families\\tfamilies\\n')\n",
    "number_of_edges = []\n",
    "number_of_families = []\n",
    "words = ''\n",
    "group_prec = ''\n",
    "family_count = 0\n",
    "H = nx.DiGraph()\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    group_id = input_file.split(' ')[0].split('-')[0]\n",
    "    if group_id != group_prec and group_prec != '':\n",
    "        f_summary.write(group_prec + '\\t' + str(len(H)) + '\\t' + str(H.size()) + '\\t')\n",
    "        #if len(H.edges()) <= 3:\n",
    "        f_summary.write(edge_writer(H))\n",
    "        f_summary.write('\\t' + str(family_count) + '\\t' + words[:-2] + '\\n')\n",
    "        number_of_edges.append(H.size())\n",
    "        number_of_families.append(family_count)\n",
    "        family_count = 0\n",
    "        words = ''\n",
    "    family_count += 1\n",
    "    group_prec = input_file.split(' ')[0].split('-')[0]\n",
    "    \n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=edge_type)\n",
    "                    word = elements[graph_1]\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=edge_type)\n",
    "                    word = elements[graph_2]\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2]])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = elements[fichier_origine] + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "                    word = sorted_lex[0].split('_')[0]\n",
    "                else:  # orientation: indirect\n",
    "                    pass\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print('not weakly connected', input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    words += nodes_writer(H) + '; '\n",
    "    write_dot(H, join('fingerprint_visualization', input_file.replace('.txt','.dot')))\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(input_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "f_summary.write(group_prec + '\\t' + str(len(H)) + '\\t' + str(H.size()) + '\\t')\n",
    "f_summary.write(edge_writer(H))\n",
    "f_summary.write('\\t' + str(family_count) + '\\t' + words[:-2] + '\\n')\n",
    "f_summary.close()\n",
    "number_of_edges.append(H.size())\n",
    "number_of_families.append(family_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.set_size_inches(10, 5)\n",
    "#ax=fig.add_axes([0,0,1,1])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(number_of_edges, number_of_families, label='group')\n",
    "ax.set_xlabel('Number of edges')\n",
    "ax.set_ylabel('Number of families in a group')\n",
    "ax.set_title('Group of families')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF generation\n",
    "dot_dir = 'graph_visualization'\n",
    "dot_files = [f for f in listdir(dot_dir) if isfile(join(dot_dir, f))]\n",
    "counter = 0\n",
    "for dot_file in dot_files:\n",
    "    os.system('dot -Tpdf \"' + join(dot_dir, dot_file) + '\" -o \"' + join(dot_dir, dot_file.replace('.dot', '.pdf')) + '\"')\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(dot_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for gSpan. Directed. Vertex: {}. edges: orientation (direct or NA), cstr_1, cstr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'families_fingerprint'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "family_labels = list()\n",
    "fam_prec = ''\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    #if 'F00055' not in input_file:\n",
    "        #continue\n",
    "    fam_prec = input_file.split('-')[0]\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0]#.replace('F', '')\n",
    "    family_labels.append(family_number)\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                    \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[cstr_1] + '-' + elements[cstr_2] \n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[cstr_2] + '-' + elements[cstr_1] \n",
    "                elif elements[orientation] == 'NA':\n",
    "                    edge_type = elements[cstr_1] + '-' + elements[cstr_2] \n",
    "                    edge_type_reverse = elements[cstr_2] + '-' + elements[cstr_1] \n",
    "                else:  # indirect\n",
    "                    pass\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                if elements[orientation] == 'NA':\n",
    "                    try:\n",
    "                        edge_label_reverse = edge_labels.index(edge_type_reverse)\n",
    "                    except ValueError:\n",
    "                        edge_label_reverse = len(edge_labels)\n",
    "                        edge_labels.append(edge_type_reverse)\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_label)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_label)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_label)\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_label_reverse)\n",
    "                else:\n",
    "                    pass\n",
    "    node_list = list(H.nodes)\n",
    "    for node_idx, node in enumerate(node_list):\n",
    "        f_out.write('v ' + str(node_idx) + ' 0\\n')\n",
    "        #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "    for edge in list(H.edges):\n",
    "        f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "        #print('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']))\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(input_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after writing file for gSpan\n",
    "edge_label_file = open('label_edge.p', 'wb')\n",
    "pickle.dump(edge_labels, edge_label_file)\n",
    "edge_label_file.close()\n",
    "\n",
    "family_label_file = open('label_family.p', 'wb')\n",
    "pickle.dump(family_labels, family_label_file)\n",
    "family_label_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for gSpan. Directed. Vertex: cat_1, cat_2. edges: cstr_1, cstr_2, orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "family_labels = list()\n",
    "fam_prec = ''\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    #if '-' in input_file and input_file.split('-')[0] == fam_prec:\n",
    "        #continue\n",
    "    fam_prec = input_file.split('-')[0]\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0]#.replace('F', '')\n",
    "    family_labels.append(family_number)\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                va = elements[graph_1] + '_' + elements[cat_1]\n",
    "                vb = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(va, vb) or H.has_edge(vb, va):\n",
    "                    continue\n",
    "                    \n",
    "                vertex_a_type = category_shortening(elements[cat_1])\n",
    "                vertex_b_type = category_shortening(elements[cat_2])\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(va, label=vertex_a_label)\n",
    "                H.add_node(vb, label=vertex_b_label)\n",
    "                    \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[cstr_1] + '-' + elements[cstr_2] \n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[cstr_2] + '-' + elements[cstr_1] \n",
    "                else:  # NA or indirect\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = sorted_cstr[0] + '-' + sorted_cstr[1] + '_' + elements[orientation]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    H.add_edge(va, vb, label=edge_label)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    H.add_edge(vb, va, label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(va, vb, label=edge_label)\n",
    "                    H.add_edge(vb, va, label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "            #print('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']))\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(input_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after writing file for gSpan\n",
    "vertex_label_file = open('label_vertex.p', 'wb')\n",
    "pickle.dump(vertex_labels, vertex_label_file)\n",
    "vertex_label_file.close()\n",
    "\n",
    "edge_label_file = open('label_edge.p', 'wb')\n",
    "pickle.dump(edge_labels, edge_label_file)\n",
    "edge_label_file.close()\n",
    "\n",
    "family_label_file = open('label_family.p', 'wb')\n",
    "pickle.dump(family_labels, family_label_file)\n",
    "family_label_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for context directly. Vertex: cat_1, cat_2. edges: orientation, cstr_1, cstr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F03887-1465\r"
     ]
    }
   ],
   "source": [
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "output_dir = 'graph_binary'\n",
    "\n",
    "for input_file in input_files:\n",
    "    fam_id = input_file.split()[0]\n",
    "    group_id = fam_id.split('-')[0]\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                va = elements[graph_1] + '_' + elements[cat_1]\n",
    "                vb = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(va, vb) or H.has_edge(vb, va):\n",
    "                    continue\n",
    "                try:\n",
    "                    freq_a = frequencies.loc[frcowvec_cat_conversion(va)]['freq']\n",
    "                except KeyError:\n",
    "                    freq_a = 0\n",
    "                try:\n",
    "                    freq_b = frequencies.loc[frcowvec_cat_conversion(vb)]['freq']\n",
    "                except KeyError:\n",
    "                    freq_b = 0\n",
    "                H.add_node(va, label=category_shortening(elements[cat_1]), frequency=freq_a)\n",
    "                H.add_node(vb, label=category_shortening(elements[cat_2]), frequency=freq_b)\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2])\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1])\n",
    "                else:\n",
    "                    # sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    H.add_edge(va, vb, label=elements[cstr_1] + '-' + elements[cstr_2] + '_' + elements[orientation])\n",
    "                    H.add_edge(vb, va, label=elements[cstr_2] + '-' + elements[cstr_1] + '_' + elements[orientation])\n",
    "    graph_file = open(join(output_dir, fam_id), 'wb')\n",
    "    pickle.dump(H, graph_file)\n",
    "    graph_file.close()\n",
    "    print(input_file.split()[0], end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for context directly. Vertex: {} . edges: cstr_1, cstr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'families_fingerprint'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "output_dir = 'fingerprint_binary'\n",
    "\n",
    "for input_file in input_files:\n",
    "    fam_id = input_file.split()[0]\n",
    "    group_id = fam_id.split('-')[0]\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                H.add_node(elements[graph_1] + '_' + elements[cat_1], label='')\n",
    "                H.add_node(elements[graph_2] + '_' + elements[cat_2], label='')\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=elements[cstr_1] + '-' + elements[cstr_2])\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=elements[cstr_2] + '-' + elements[cstr_1])\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=elements[cstr_1] + '-' + elements[cstr_2])\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=elements[cstr_2] + '-' + elements[cstr_1])\n",
    "                else:  # orientation: indirect\n",
    "                    pass\n",
    "    if H.size() < 1:  # no edge\n",
    "        continue\n",
    "    graph_file = open(join(output_dir, fam_id), 'wb')\n",
    "    pickle.dump(H, graph_file)\n",
    "    graph_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for all families, directed, no cstr in edges\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    write_dot(H, join('graphs_directed', input_file.replace('.txt','.dot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle1: create directed graph for gSpan input, cstr in vertices\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0].replace('F', '')\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                \n",
    "                vertex_a_type = line_elements[8] + '_' + line_elements[14]\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                vertex_b_type = line_elements[10] + '_' + line_elements[17]\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(line_elements[3] + '_' + line_elements[8], label=vertex_a_label)\n",
    "                H.add_node(line_elements[6] + '_' + line_elements[10], label=vertex_b_label)\n",
    "                    \n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "f_out.close()\n",
    "print(vertex_labels)\n",
    "print(edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
