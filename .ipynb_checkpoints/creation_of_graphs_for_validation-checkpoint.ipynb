{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e56cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import printProgressBar\n",
    "\n",
    "# column number\n",
    "rid = 0\n",
    "fid = 1\n",
    "lid_1 = 2\n",
    "graph_1 = 3\n",
    "ori_graph_1 = 4\n",
    "lid_2 = 5\n",
    "graph_2 = 6\n",
    "ori_graph_2 = 7\n",
    "cat_1 = 8\n",
    "ori_cat_1 = 9\n",
    "cat_2 = 10\n",
    "ori_cat_2 = 11\n",
    "ori_cple = 12\n",
    "type_cstr_1 = 13\n",
    "cstr_1 = 14\n",
    "ori_cstr_1 = 15\n",
    "type_cstr_2 = 16\n",
    "cstr_2 = 17\n",
    "ori_cstr_2 = 18\n",
    "complexite = 19\n",
    "ori_complexite = 20\n",
    "orientation = 21\n",
    "ori_orientation = 22\n",
    "semty_1 = 23\n",
    "ori_semty_1 = 24\n",
    "semty_2 = 25\n",
    "ori_semty_2 = 26\n",
    "sous_semty_1 = 27\n",
    "sous_semty_2 = 28\n",
    "ori_sous_semty_1 = 29\n",
    "ori_sous_semty_2 = 30\n",
    "semtyrss_1 = 31\n",
    "semtyrss_2 = 32\n",
    "ori_semtyrss_1 = 33\n",
    "ori_semtyrss_2 = 34\n",
    "rel_sem_n1 = 35\n",
    "rel_sem_n2 = 36\n",
    "ori_relsem = 37\n",
    "def_conc = 38\n",
    "ori_def_conc = 39\n",
    "def_abs = 40\n",
    "ori_def_abs = 41\n",
    "commentaires = 42\n",
    "fichier_origine = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac619e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_shortening(cat):\n",
    "    if cat != 'Num' and cat[0] == 'N':\n",
    "        return 'N'\n",
    "    return cat\n",
    "\n",
    "def origine(origine_input):\n",
    "    if origine_input == 'CV':\n",
    "        return 'C'\n",
    "    return origine_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05447c",
   "metadata": {},
   "source": [
    "# spurious lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2eafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_folder = 'families'\n",
    "spurious_folder = 'spurious'\n",
    "model_folder = 'graph_visualization_web'\n",
    "df = pd.read_excel('concept_comparison_maxgraph_spurious.xlsx')\n",
    "selected_rows = df[df['spurious_node_freq'] < 1]\n",
    "#selected_rows.to_excel('spurious_freq_0.xlsx', index=False)\n",
    "selected_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(output_folder, in_dot_file_name, out_dot_file_name, spurious=''):\n",
    "    G = pickle.load(open(join('graph_binary', in_dot_file_name.split()[0]), 'rb'))\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(family_folder, in_dot_file_name.replace('dot', 'txt')), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(v1, v2) or H.has_edge(v2, v1):\n",
    "                    continue\n",
    "                H.add_node(v1, label=elements[graph_1] + '\\n' + category_shortening(elements[cat_1]) + ', ' + str(G.nodes[v1]['frequency']))\n",
    "                H.add_node(v2, label=elements[graph_2] + '\\n' + category_shortening(elements[cat_2]) + ', ' + str(G.nodes[v2]['frequency']))\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    H.add_edge(v1, v2, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    H.add_edge(v2, v1, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'indirect':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dotted', label=edge_type)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "                else:\n",
    "                    print(input_file, elements[orientation])\n",
    "    if spurious == '':\n",
    "        write_dot(H, join(output_folder, out_dot_file_name))\n",
    "    else:\n",
    "        for in_edge in H.in_edges(spurious):\n",
    "            H.edges[in_edge]['color'] = 'red'\n",
    "        for out_edge in H.out_edges(spurious):\n",
    "            H.edges[out_edge]['color'] = 'red'\n",
    "        H.nodes[spurious]['color'] = 'red'\n",
    "        write_dot(H, join(output_folder, out_dot_file_name))\n",
    "\n",
    "counter = 0\n",
    "for index, row in selected_rows.iterrows():\n",
    "    create_graph(spurious_folder, row['child'], row['parent'].split()[0] + '_' + row['child'].split()[0] + '.dot', row['spurious_node'])\n",
    "    counter += 1\n",
    "    printProgressBar(counter, selected_rows.shape[0], prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "\n",
    "list_of_parents = selected_rows['parent'].unique()\n",
    "counter = 0\n",
    "for parent in list_of_parents:\n",
    "    create_graph(model_folder, parent, parent)\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(list_of_parents), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba96fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNG generation\n",
    "dot_files = [f for f in listdir(spurious_folder) if isfile(join(spurious_folder, f)) and '.dot' in f]\n",
    "counter = 0\n",
    "for dot_file in dot_files:\n",
    "    os.system('dot -Tpng \"' + join(spurious_folder, dot_file) + '\" -o \"' + join(spurious_folder, dot_file.replace('.dot', '.png')) + '\"')\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(dot_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNG generation\n",
    "dot_files = [f for f in listdir(model_folder) if isfile(join(model_folder, f)) and '.dot' in f]\n",
    "counter = 0\n",
    "for dot_file in dot_files:\n",
    "    os.system('dot -Tpng \"' + join(model_folder, dot_file) + '\" -o \"' + join(model_folder, dot_file.replace('.dot', '.png')) + '\"')\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(dot_files), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c11f86",
   "metadata": {},
   "source": [
    "# missing lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e988d3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_folder = 'families'\n",
    "missing_folder = 'missing_lexemes'\n",
    "model_folder = 'graph_visualization_web'\n",
    "df = pd.read_excel('concept_comparison_maxgraph_missing.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33ecc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772221, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.read_csv('frequencies-frcowvec-filtered.csv', header=0, index_col=0)\n",
    "frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c594f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frcowvec_categories = {'Nm': 'NOM', 'Nf': 'NOM', 'Nmp': 'NOM', 'Nfp': 'NOM', 'Nx': 'NOM', 'More': 'NOM',\n",
    "                       'Npm': 'NAM', 'Npf': 'NAM', 'Npx': 'NAM', 'Npmp': 'NAM', 'Npfp': 'NAM',\n",
    "                       'Adj': 'ADJ', 'V': 'VER', 'Num': 'NUM', 'Pro': 'PRO', 'Adv': 'ADV'}\n",
    "\n",
    "def frcowvec_cat_conversion(lexeme):\n",
    "    old_cat = lexeme.split('_')[-1]\n",
    "    new_cat = frcowvec_categories.get(old_cat)\n",
    "    return lexeme.split('_')[0] + '_' + new_cat\n",
    "\n",
    "def get_frequency(input_str):\n",
    "    lexemes = input_str.split(', ')\n",
    "    ret_str = ''\n",
    "    for lexeme in lexemes:\n",
    "        if lexeme == 'XX':\n",
    "            ret_str += '0, '\n",
    "        else:\n",
    "            try:\n",
    "                freq = frequencies.loc[frcowvec_cat_conversion(lexeme)]['freq']\n",
    "                ret_str += str(freq) + ', '\n",
    "            except KeyError:\n",
    "                ret_str += '0, '\n",
    "    return ret_str[:-2]\n",
    "\n",
    "def analogy(input_str):\n",
    "    # input_str ex : \"micocoulier_Nm : micocoule_Nf = cotonéaster_Nm : ?, micocoulier_Nm : micocouleraie_Nf = cotonéaster_Nm : ?\"\n",
    "    complete_strs = input_str.replace(' ','').split(',')\n",
    "    ret_str = ''\n",
    "    for complete_str in complete_strs:\n",
    "        a1 = '{' + complete_str.split('=')[0].split(':')[0].split('_')[0] + '}'\n",
    "        a2 = '{' + complete_str.split('=')[0].split(':')[1].split('_')[0] + '}'\n",
    "        b1 = '{' + complete_str.split('=')[1].split(':')[0].split('_')[0] + '}'\n",
    "        a2_cat = complete_str.split('=')[0].split(':')[1].split('_')[1]\n",
    "        match = SequenceMatcher(None, a1, a2).find_longest_match(0, len(a1), 0, len(a2))\n",
    "        common = a1[match.a:match.a+match.size]\n",
    "        a1_suffix = a1.replace(common, '')\n",
    "        a2_suffix = a2.replace(common, '')\n",
    "        b2 = b1.replace(a1_suffix, a2_suffix)\n",
    "        if b2 == b1 and a1 != a2:\n",
    "            ret_str += 'XX, '\n",
    "        else:\n",
    "            ret_str += b2.replace('{', '').replace('}', '') + '_' + a2_cat + ', '\n",
    "    return ret_str[:-2]\n",
    "    \n",
    "def create_graph(output_folder, in_dot_file_name, out_dot_file_name, spurious=''):\n",
    "    G = pickle.load(open(join('graph_binary', in_dot_file_name.split()[0]), 'rb'))\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(family_folder, in_dot_file_name.replace('dot', 'txt')), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if H.has_edge(v1, v2) or H.has_edge(v2, v1):\n",
    "                    continue\n",
    "                H.add_node(v1, label=elements[graph_1] + '\\n' + category_shortening(elements[cat_1]) + ', ' + str(G.nodes[v1]['frequency']))\n",
    "                H.add_node(v2, label=elements[graph_2] + '\\n' + category_shortening(elements[cat_2]) + ', ' + str(G.nodes[v2]['frequency']))\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    H.add_edge(v1, v2, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    H.add_edge(v2, v1, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'indirect':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dotted', label=edge_type)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = origine(elements[fichier_origine]) + ': ' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "                else:\n",
    "                    print(input_file, elements[orientation])\n",
    "    if spurious == '':\n",
    "        write_dot(H, join(output_folder, out_dot_file_name))\n",
    "    else:\n",
    "        for in_edge in H.in_edges(spurious):\n",
    "            H.edges[in_edge]['color'] = 'red'\n",
    "        for out_edge in H.out_edges(spurious):\n",
    "            H.edges[out_edge]['color'] = 'red'\n",
    "        H.nodes[spurious]['color'] = 'red'\n",
    "        write_dot(H, join(output_folder, out_dot_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c51a81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missing'] = df['analogy'].apply(analogy)\n",
    "df['frequency'] = df['missing'].apply(get_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be1d8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('proposition.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df517f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "list_of_child = df['child'].unique()\n",
    "counter = 0\n",
    "for child in list_of_child:\n",
    "    create_graph(model_folder, child, child)\n",
    "    counter += 1\n",
    "    printProgressBar(counter, len(list_of_child), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0b694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
