{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# column number\n",
    "rid = 0\n",
    "fid = 1\n",
    "lid_1 = 2\n",
    "graph_1 = 3\n",
    "ori_graph_1 = 4\n",
    "lid_2 = 5\n",
    "graph_2 = 6\n",
    "ori_graph_2 = 7\n",
    "cat_1 = 8\n",
    "ori_cat_1 = 9\n",
    "cat_2 = 10\n",
    "ori_cat_2 = 11\n",
    "ori_cple = 12\n",
    "type_cstr_1 = 13\n",
    "cstr_1 = 14\n",
    "ori_cstr_1 = 15\n",
    "type_cstr_2 = 16\n",
    "cstr_2 = 17\n",
    "ori_cstr_2 = 18\n",
    "complexite = 19\n",
    "ori_complexite = 20\n",
    "orientation = 21\n",
    "ori_orientation = 22\n",
    "semty_1 = 23\n",
    "ori_semty_1 = 24\n",
    "semty_2 = 25\n",
    "ori_semty_2 = 26\n",
    "sous_semty_1 = 27\n",
    "sous_semty_2 = 28\n",
    "ori_sous_semty_1 = 29\n",
    "ori_sous_semty_2 = 30\n",
    "semtyrss_1 = 31\n",
    "semtyrss_2 = 32\n",
    "ori_semtyrss_1 = 33\n",
    "ori_semtyrss_2 = 34\n",
    "rel_sem_n1 = 35\n",
    "rel_sem_n2 = 36\n",
    "ori_relsem = 37\n",
    "def_conc = 38\n",
    "ori_def_conc = 39\n",
    "def_abs = 40\n",
    "ori_def_abs = 41\n",
    "commentaires = 42\n",
    "fichier_origine = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: Directed, Vertex: lexeme, categorie, semty. Edges: rel_sem, cstr\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                if elements[23] == '' or elements[25] == '' or elements[36] == '':\n",
    "                    continue\n",
    "                \n",
    "                vertices1 = list()\n",
    "                vertices2 = list()\n",
    "                if '|' in line_elements[23]:\n",
    "                    vertices1.append(elements[graph_1] + '_' + elements[cat_1] + '_' + elements[semty_1].split('|')[0])\n",
    "                    vertices1.append(elements[graph_1] + '_' + elements[cat_1] + '_' + elements[semty_1].split('|')[1])\n",
    "                else:\n",
    "                    vertices1.append(line_elements[graph_1] + '_' + line_elements[cat_1] + '_' + elements[semty_1])\n",
    "                if '|' in line_elements[25]:\n",
    "                    vertices2.append(elements[graph_2] + '_' + elements[cat_2] + '_' + elements[semty_2].split('|')[0])\n",
    "                    vertices2.append(elements[graph_2] + '_' + elements[cat_2] + '_' + elements[semty_2].split('|')[1])\n",
    "                else:\n",
    "                    vertices2.append(elements[graph_2] + '_' + elements[cat_2] + '_' + elements[semty_2])\n",
    "                \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = line_elements[rel_sem_n2] + '_' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    for v1 in vertices1:\n",
    "                        for v2 in vertices2:\n",
    "                            H.add_edge(v1, v2, label=edge_type)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[rel_sem_n2] + '_' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    for v1 in vertices1:\n",
    "                        for v2 in vertices2:\n",
    "                            H.add_edge(v2, v1, label=edge_type)\n",
    "                else:\n",
    "                    edge_type1 = elements[rel_sem_n2] + '_' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    edge_type2 = elements[rel_sem_n2] + '_' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    for v1 in vertices1:\n",
    "                        for v2 in vertices2:\n",
    "                            H.add_edge(v1, v2, label=edge_type1)\n",
    "                            H.add_edge(v2, v1, label=edge_type2)\n",
    "    write_dot(H, join('graphs edge_relsem_cstr', input_file.replace('.txt','.dot')))\n",
    "    H.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: directed, vertex: lexeme, category. edges: orientation, complexite, cstr\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01942 autostabilité_Nx.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[complexite] + '_' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=edge_type)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[complexite] + '_' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=edge_type)\n",
    "                elif elements[orientation] == 'indirect':\n",
    "                    sorted_lex = sorted([elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2]])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[complexite] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2]])\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[complexite] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    H.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', color='gray', label=edge_type)\n",
    "                else:\n",
    "                    print(input_file, elements[orientation])\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    write_dot(H, join('graph visualization', input_file.replace('.txt','.dot')))\n",
    "    H.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nf', 'V', 'Nm', 'Adj', 'Nx', 'Npx', 'Nmp', 'Nfp', 'Npm', 'Npf', 'Pro', 'Adv', 'Num']\n",
      "['simple_X-X', 'simple_X-Xment', 'simple_indirect_Xeur-Xment', 'simple_X-Xeur', 'simple_X-Xage', 'simple_NA_X-X', 'simple_X-Xable', 'simple_X-aX', 'simple_X-Xier', 'simple_X-Xière', 'simple_indirect_Xeuse-Xment', 'simple_X-Xeuse', 'simple_indirect_Xeur-Xeuse', 'simple_X-Xique', 'simple_X-Xataire', 'simple_indirect_Xage-Xment', 'simple_indirect_Xage-Xeuse', 'simple_X-Xure', 'simple_indirect_Xage-Xeur', 'simple_X-reX', 'simple_X-Xion', 'simple_X-dé1X', 'simple_X-inX', 'simple_X-Xette', 'simple_X-Xaie', 'simple_indirect_Xeur-Xif', 'simple_indirect_Xeur-Xion', 'simple_indirect_Xeur-Xrice', 'simple_indirect_Xif-Xion', 'simple_X-Xif', 'simple_indirect_Xif-Xrice', 'simple_indirect_Xion-Xrice', 'simple_X-Xrice', 'simple_X-Xade', 'simple_X-Xerie', 'simple_X-Xaille', 'simple_X-Xounette', 'simple_X-Xet', 'simple_X-Xinet', 'simple_X-Xaire', 'complexe_indirect_X-Xion', 'simple_indirect_Xeur-Xeur', 'simple_X-Xal', 'simple_X-Xariat', 'simple_X-Xat', 'simple_X-Xiat', 'simple_indirect_Xaire-Xat', 'simple_X-Xance', 'simple_X-Xence', 'motiv-sem_X-transXalier', 'simple_indirect_aX-dé1X', 'simple_X-Xité', 'simple_X-Xer', 'simple_X-Xerette', 'motiv-sem_X-subXaire', 'simple_indirect_Xaire-Xation', 'simple_X-Xée', 'simple_X-Xère', 'motiv-sem_indirect_Xal-Xion', 'simple_X-Xelette', 'simple_indirect_Xeur-Xorat', 'simple_indirect_Xariat-Xeur', 'motiv-sem_indirect_Xique-Xiste', 'motiv-sem_X-quadriXaire', 'motiv-sem_X-quinquXaire', 'simple_X-Xinette', 'simple_indirect_Xeuse-Xif', 'simple_X-transX', 'simple_indirect_Xier-Xorat', 'motiv-sem_indirect_Xage-Xal', 'simple_X-Xorat', 'simple_X-Xelet', 'motiv-sem_X-Xural', 'motiv-sem_X-Xistique', 'simple_X-Xistique', 'simple_indirect_Xion-Xment', 'simple_indirect_Xeuse-Xion', 'motiv-sem_indirect_Xal-Xie', 'simple_indirect_X-Xeur', 'simple_indirect_Xaire-Xion', 'simple_X-Xifier', 'motiv-sem_NA_X-X', 'simple_X-Xeux', 'simple_indirect_Xiat-Xier', 'simple_X-enX', 'simple_X-Xaison', 'simple_X-dé2X', 'simple_indirect_Xette-Xier', 'simple_indirect_Xage-Xière', 'simple_indirect_Xette-Xeur', 'simple_indirect_Xariat-Xier', 'simple_indirect_Xat-Xier', 'simple_indirect_Xette-Xinette', 'motiv-sem_X-Xique', 'simple_X-Xouillette', 'motiv-sem_X-dé1Xifier', 'complexe_X-Xonnière', 'complexe_X-Xetier', 'simple_X-éX', 'simple_X-Xonnet', 'simple_X-Xis', 'motiv-sem_X-dé1Xiser', 'motiv-sem_X-extraXaire', 'simple_indirect_Xage-Xion', 'simple_indirect_X-Xise', 'simple_indirect_Xeuse-Xrice', 'simple_X-Xing', 'simple_indirect_X-Xière', 'simple_X-Xoine', 'simple_X-Xiser', 'simple_X-Xeraie', 'simple_indirect_X-Xier', 'motiv-sem_X-biXaire', 'motiv-sem_X-triXaire', 'motiv-sem_X-uniXaire', 'simple_X-autoX', 'motiv-sem_indirect_Xeur-Xique', 'simple_indirect_Xeur-Xure', 'motiv-sem_indirect_Xoral-Xure', 'simple_X-disX', 'simple_X-interX', 'simple_X-Xeret', 'simple_indirect_X-Xerie', 'simple_X-Xois', 'motiv-sem_indirect_Xitique-Xois', 'simple_indirect_Xie-Xier', 'motiv-sem_X-infraXaire', 'motiv-sem_X-supraXaire', 'simple_X-thermoX', 'accidentel_NA_X-Xoire', 'simple_X-Xant', 'motiv-sem_indirect_Xal-Xant', 'motiv-sem_X-antiXaire', 'simple_indirect_Xeur-Xoriat', 'simple_indirect_Xaie-Xier', 'simple_indirect_Xier-Xine', 'simple_X-Xise', 'simple_indirect_X-Xinette', 'complexe_X-Xillette', 'accidentel_NA_X-X', 'simple_X-contreX', 'simple_indirect_Xat-Xeur', 'motiv-sem_X-multiXaire', 'complexe_X-Xionnaire', 'simple_indirect_X-Xrice', 'motiv-sem_X-interXaire', 'simple_X-Xel', 'simple_indirect_Xelette-Xière', 'simple_X-Xiquet', 'motiv-sem_X-pluriXaire', 'simple_indirect_Xat-Xiste', 'motiv-sem_X-sexXaire', 'motiv-sem_indirect_Xion-Xoral', 'motiv-sem_X-intraXaire', 'simple_indirect_Xeur-Xise', 'motiv-sem_indirect_Xise-Xoral', 'motiv-sem_X-preXière', 'simple_indirect_Xisme-Xité', 'simple_indirect_Xiste-Xité', 'motiv-sem_indirect_Xistique-Xité', 'motiv-sem_indirect_Xisme-Xistique', 'simple_X-équiX', 'complexe_X-Xaire', 'motiv-sem_indirect_Xal-Xise', 'complexe_X-Xonnier', 'simple_X-Xanat', 'simple_indirect_Xation-Xette', 'simple_X-Xounet', 'simple_indirect_Xage-Xier', 'complexe_X-Xilier', 'simple_X-Xie', 'simple_indirect_Xariat-Xer', 'simple_indirect_Xette-Xière', 'motiv-sem_indirect_X-X', 'simple_X-Xouette', 'motiv-sem_X-postXaire', 'motiv-sem_X-préXaire', 'motiv-sem_X-Xulaire', 'simple_X-Xule', 'simple_X-Xillette', 'simple_X-Xiette', 'simple_Xage-X', 'complexe_X-Xetière', 'simple_X-Xichette', 'motiv-sem_indirect_Xique-Xisme', 'motiv-sem_X-juxtaXaire', 'motiv-sem_X-matriXaire', 'motiv-sem_X-patriXaire', 'simple_indirect_Xette-Xonette', 'simple_X-Xouquette', 'motiv-sem_X-coXier', 'simple_X-Xange', 'motiv-sem_X-circumXaire', 'motiv-sem_indirect_Xal-Xat', 'simple_X-nonX', 'simple_indirect_Xaillette-Xette', 'motiv-sem_X-aXaire', 'motiv-sem_X-circomXaire', 'motiv-sem_X-monoXaire', 'motiv-sem_X-omniXaire', 'motiv-sem_X-périXaire', 'motiv-sem_X-tétraXaire', 'motiv-sem_X-transXaire', 'simple_X-surX', 'accidentel_NA_X-Xion', 'simple_X-Xaillette', 'simple_X-coX', 'complexe_indirect_Xerie-Xiser', 'complexe_X-Xise', 'motiv-sem_X-diXaire', 'motiv-sem_X-polyXaire', 'complexe_indirect_X-Xage', 'accidentel_NA_X-Xande', 'simple_X-Xellette', 'simple_indirect_Xier-Xée', 'motiv-sem_X-sousXaire', 'motiv-form_X-Xistique', 'simple_X-Xon', 'simple_indirect_Xage-Xette', 'simple_X-Xoulet', 'simple_indirect_Xette-Xie', 'simple_indirect_Xette-Xot', 'simple_X-Xicat', 'simple_X-Xoyer', 'simple_X-Xassier', 'simple_indirect_Xon-Xounette', 'simple_indirect_Xant-Xat', 'simple_X-Xisme', 'simple_X-Xiste', 'complexe_X-éXette', 'simple_X-Xonnette', 'simple_X-préX', 'complexe_X-Xinet', 'complexe_X-Xinette', 'simple_indirect_Xat-Xé', 'simple_X-Xé', 'motiv-sem_indirect_Xal-Xé', 'motiv-sem_indirect_Xoire-Xoral', 'simple_indirect_Xariat-Xé', 'motiv-sem_indirect_Xique-Xment', 'motiv-sem_X-Xétique', 'simple_X-Xinat', 'motiv-sem_X-nasoXier', 'complexe_indirect_X-Xisme', 'simple_indirect_X-Xaire', 'simple_X-semiX', 'motiv-sem_X-aquaXaire', 'simple_X-paraX', 'simple_indirect_X-Xat', 'motiv-sem_X-Xoral', 'motiv-sem_indirect_Xaire-Xion', 'complexe_X-Xariat', 'simple_indirect_Xette-Xoter', 'simple_X-Xouillet', 'simple_indirect_Xette-Xon', 'simple_indirect_Xerie-Xiser', 'simple_indirect_Xiser-Xisme', 'simple_indirect_X-Xette', 'simple_X-hyperX', 'simple_X-hypoX', 'accidentel_NA_X-Xaire', 'simple_X-Xète', 'simple_indirect_Xion-Xé', 'simple_X-synX', 'simple_indirect_Xie-Xé', 'complexe_X-Xettes', 'simple_X-bioX', 'motiv-sem_X-dé1Xaliser', 'motiv-sem_X-Xaliser', 'motiv-sem_X-dé1Xiner', 'simple_X-polyX', 'complexe_X-Xassier', 'simple_indirect_Xeur-Xoire', 'simple_indirect_Xment-Xrice', 'simple_indirect_Xette-Xeuse', 'motiv-sem_indirect_Xique-Xité', 'accidentel_NA_X-Xeur', 'simple_X-Xatique', 'accidentel_NA_X-Xice', 'accidentel_NA_X-Xif', 'motiv-sem_indirect_Xeur-Xistique', 'motiv-sem_indirect_Xeuse-Xistique', 'simple_indirect_X-Xité', 'complexe_X-Xisme', 'simple_X-Xiquette', 'motiv-sem_X-coXaire', 'simple_indirect_Xage-Xrice', 'simple_indirect_X-Xeuse', 'simple_indirect_Xion-Xion', 'simple_indirect_Xage-Xonner', 'motiv-sem_X-Xariser', 'accidentel_X-Xat', 'accidentel_X-Xiat', 'motiv-sem_X-Xiat', 'simple_X-Xolet', 'motiv-sem_X-biXet', 'simple_X-Xiculet', 'motiv-sem_X-sousXier', 'motiv-sem_X-hypoXaire', 'simple_indirect_Xat-Xité', 'simple_indirect_Xal-Xat', 'motiv-sem_X-équiXaire', 'motiv-sem_X-orthoXaire', 'simple_indirect_Xaire-Xorat', 'motiv-sem_X-exXaire', 'simple_X-Xeté', 'simple_indirect_Xal-Xeté', 'simple_X-Xien', 'motiv-sem_indirect_Xal-Xien', 'simple_X-Xaume', 'motiv-sem_indirect_Xal-Xaume', 'simple_X-Xoïde', 'motiv-sem_X-Xoïdal', 'motiv-sem_indirect_Xien-Xique', 'simple_indirect_Xat-Xie', 'motiv-sem_X-sousXière', 'motiv-sem_indirect_Xat-Xique', 'simple_X-Xrette', 'simple_indirect_Xiat-Xien', 'motiv-sem_indirect_Xique-Xétique', 'motiv-sem_indirect_Xgenèse-Xgénique', 'motiv-sem_X-Xicat', 'simple_indirect_Xette-Xlogie', 'simple_X-Xeute', 'motiv-sem_indirect_Xeutique-Xique', 'motiv-sem_X-Xeutique', 'motiv-sem_indirect_Xeute-Xique', 'motiv-sem_indirect_X-Xique', 'simple_indirect_Xisme-Xiste', 'motiv-sem_indirect_Xant-Xique', 'motiv-sem_indirect_Xique-Xite', 'motiv-sem_indirect_Xeux-Xique', 'accidentel_X-Xulat', 'accidentel_X-Xolat', 'motiv-sem_X-Xariat', 'simple_indirect_Xette-Xlogique', 'complexe_X-Xaticat', 'motiv-sem_indirect_Xerie-Xique', 'accidentel_X-Xouette', 'simple_indirect_Xique-Xiste', 'simple_X-Xate', 'simple_X-vraiX', 'simple_X-Xraie', 'simple_indirect_Xier-Xraie', 'simple_indirect_Xat-Xien', 'complexe_X-Xérat', 'simple_indirect_Xant-Xorat', 'simple_indirect_Xanat-Xé', 'simple_X-Xikat', 'simple_indirect_Xariat-Xiste', 'simple_X-Xéat', 'motiv-sem_X-Xainat', 'motiv-sem_X-Xanat', 'simple_indirect_Xicat-Xien', 'simple_indirect_Xant-Xariat', 'simple_indirect_Xat-Xique', 'motiv-sem_X-Xalat', 'accidentel_X-Xissariat', 'simple_indirect_Xat-Xel', 'simple_indirect_Xariat-Xel', 'simple_indirect_Xariat-Xent', 'simple_indirect_Xiat-Xiste', 'simple_X-Xoriat', 'simple_X-viceX', 'motiv-sem_X-Xériat', 'motiv-sem_X-Xelat', 'motiv-sem_X-Xionat', 'simple_indirect_Xariat-Xet', 'complexe_X-Xailler', 'simple_X-sousX', 'simple_X-protoXicat', 'complexe_X-Xiat', 'motiv-sem_X-Xat', 'simple_X-Xlette', 'simple_indirect_Xette-Xounette', 'motiv-sem_X-Xinat', 'simple_indirect_Xable-Xalat', 'accidentel_X-Xariat', 'complexe_X-Xagier', 'complexe_X-Xalette', 'complexe_X-Xinettes', 'simple_indirect_Xais-Xette', 'simple_indirect_Xiau-Xiette', 'simple_X-Xailler', 'simple_indirect_Xelette-Xette', 'simple_indirect_Xette-Xfère', 'simple_NA_X-Xètes', 'simple_X-Xerète', 'simple_X-Xlet', 'simple_indirect_Xet-Xium', 'motiv-sem_X-inXaire', 'motiv-sem_X-podoXaire', 'complexe_X-Xinière', 'simple_indirect_Xaire-Xette', 'simple_indirect_Xade-Xette', 'simple_indirect_Xette-Xé', 'simple_indirect_Xette-Xus', 'simple_X-Xenet', 'simple_X-Xonet', 'simple_X-Xettes', 'complexe_X-Xet', 'motiv-sem_X-quartXier', 'motiv-sem_X-superXaire', 'simple_X-Xairie', 'motiv-sem_X-ultraXaire', 'motiv-sem_X-bioXaire', 'motiv-sem_X-centroXaire', 'motiv-sem_X-proXaire', 'motiv-sem_X-trichoXaire']\n"
     ]
    }
   ],
   "source": [
    "# toggle1: for gSpan. Directed. Vertex: lexeme, category. edges: orientation, complexite, cstr\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0].replace('F', '')\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                \n",
    "                vertex_a_type = elements[cat_1]\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                vertex_b_type = elements[cat_2]\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(elements[graph_1] + '_' + elements[cat_1], label=vertex_a_label)\n",
    "                H.add_node(elements[graph_2] + '_' + elements[cat_2], label=vertex_b_label)\n",
    "                    \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_1] + '-' + elements[cstr_2] \n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_2] + '-' + elements[cstr_1] \n",
    "                else:  # NA or indirect\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type = elements[complexite] + '_' + elements[orientation] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_label)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_label)\n",
    "                    H.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "            #print('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']))\n",
    "f_out.close()\n",
    "print(vertex_labels)\n",
    "print(edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: using write_dot for all families, directed, no cstr in edges\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "for input_file in input_files:\n",
    "    H = nx.DiGraph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_type)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_type)\n",
    "        try:\n",
    "            if not nx.is_weakly_connected(H):\n",
    "                print(input_file)\n",
    "        except:\n",
    "            print('null graph', input_file)\n",
    "    write_dot(H, join('graphs_directed', input_file.replace('.txt','.dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# toggle1: create directed graph for gSpan input, cstr in vertices\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "\n",
    "edge_labels = list()\n",
    "vertex_labels = list()\n",
    "\n",
    "f_out = codecs.open('for_gSpan.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    #if input_file != 'F01531 instrumentateur_Nm.txt':\n",
    "        #continue\n",
    "    H = nx.DiGraph()\n",
    "    family_number = input_file.split()[0].replace('F', '')\n",
    "    f_out.write('t # ' + family_number + '\\n')\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                line_elements = line.replace('\\n','').split('\\t')\n",
    "                \n",
    "                vertex_a_type = line_elements[8] + '_' + line_elements[14]\n",
    "                try:\n",
    "                    vertex_a_label = vertex_labels.index(vertex_a_type)\n",
    "                except ValueError:\n",
    "                    vertex_a_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_a_type)\n",
    "                vertex_b_type = line_elements[10] + '_' + line_elements[17]\n",
    "                try:\n",
    "                    vertex_b_label = vertex_labels.index(vertex_b_type)\n",
    "                except ValueError:\n",
    "                    vertex_b_label = len(vertex_labels)\n",
    "                    vertex_labels.append(vertex_b_type)\n",
    "                H.add_node(line_elements[3] + '_' + line_elements[8], label=vertex_a_label)\n",
    "                H.add_node(line_elements[6] + '_' + line_elements[10], label=vertex_b_label)\n",
    "                    \n",
    "                orientation = line_elements[21]\n",
    "                if orientation == 'as2de' or orientation == 'as2des' or orientation == 'de2as' or orientation == 'des2as':\n",
    "                    orientation = 'direct'\n",
    "                edge_type = orientation + '_' + line_elements[19]\n",
    "                try:\n",
    "                    edge_label = edge_labels.index(edge_type)\n",
    "                except ValueError:\n",
    "                    edge_label = len(edge_labels)\n",
    "                    edge_labels.append(edge_type)\n",
    "                    \n",
    "                if line_elements[21] == 'as2de' or line_elements[21] == 'as2des':\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                elif line_elements[21] == 'de2as' or line_elements[21] == 'des2as':\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "                else:\n",
    "                    H.add_edge(line_elements[3] + '_' + line_elements[8], line_elements[6] + '_' + line_elements[10], label=edge_label)\n",
    "                    H.add_edge(line_elements[6] + '_' + line_elements[10], line_elements[3] + '_' + line_elements[8], label=edge_label)\n",
    "        node_list = list(H.nodes)\n",
    "        for node_idx, node in enumerate(node_list):\n",
    "            f_out.write('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']) + '\\n')\n",
    "            #print('v ' + str(node_idx) + ' ' + str(H.nodes[node]['label']))\n",
    "        for edge in list(H.edges):\n",
    "            f_out.write('e ' + str(node_list.index(edge[0])) + ' ' + str(node_list.index(edge[1])) + ' ' + str(H[edge[0]][edge[1]]['label']) + '\\n')\n",
    "f_out.close()\n",
    "print(vertex_labels)\n",
    "print(edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# after writing file for gSpan\n",
    "vertex_label_file = open('label_vertex.p', 'wb')\n",
    "pickle.dump(vertex_labels, vertex_label_file)\n",
    "vertex_label_file.close()\n",
    "\n",
    "edge_label_file = open('label_edge.p', 'wb')\n",
    "pickle.dump(edge_labels, edge_label_file)\n",
    "edge_label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conversion from .dot to .pdf\n",
    "dot_dir = 'graph visualization'\n",
    "dot_files = [f for f in listdir(dot_dir) if isfile(join(dot_dir, f))]\n",
    "for dot_file in dot_files:\n",
    "    os.system('dot -Tpdf \"' + join(dot_dir, dot_file) + '\" -o \"' + join(dot_dir, dot_file.replace('.dot', '.pdf')) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
