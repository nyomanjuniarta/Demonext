{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3da0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from networkx.algorithms import isomorphism\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cow_dict = dict()\n",
    "# counter = 0\n",
    "with codecs.open('frequencies-frcowvec-filtered.csv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        elements = line.strip('\\n').split(',')\n",
    "        if elements[1] == 'freq':\n",
    "            continue\n",
    "        lexeme = elements[0].split('_')[0]\n",
    "        try:\n",
    "            if cow_dict[lexeme] < int(elements[1]):\n",
    "                cow_dict[lexeme] = int(elements[1])\n",
    "        except KeyError:\n",
    "            cow_dict[lexeme] = int(elements[1])\n",
    "#         print(counter, end='\\r')\n",
    "#         counter += 1\n",
    "# print(counter)\n",
    "print(len(cow_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c48639",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonette_lexemes = set()\n",
    "with codecs.open('lexemes.csv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        elements = line.split('\\t')\n",
    "        if elements[0] == 'lid':\n",
    "            continue\n",
    "        demonette_lexemes.add(elements[2])\n",
    "        \n",
    "glawi_constructions = list()\n",
    "with codecs.open('glawi-constructions.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glawi_constructions.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25663efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(pattern, word):  # pattern = 'preXisation', word = 'precognisation' => True\n",
    "    if pattern == 'X':\n",
    "        return True\n",
    "    counter = 0\n",
    "    try:\n",
    "        for c in pattern:\n",
    "            if c == 'X':\n",
    "                break\n",
    "            if c != word[counter]:\n",
    "                return False\n",
    "            counter += 1\n",
    "        counter = -1\n",
    "        while True:\n",
    "            if pattern[counter] == 'X':\n",
    "                break\n",
    "            if pattern[counter] != word[counter]:\n",
    "                return False\n",
    "            counter -= 1\n",
    "    except IndexError:  # Xtractif & actif\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def generate_lexemes(nodes):\n",
    "    return_dict = dict()\n",
    "    lexemes = set()\n",
    "    for n in nodes:\n",
    "        lexemes.add(n.split('_')[0])\n",
    "    for lexeme in lexemes:\n",
    "        best_const_length = -1\n",
    "        best_const = ''\n",
    "        for c in glawi_constructions:\n",
    "            const1 = c.split('-')[0]\n",
    "#             print('lexeme & c', lexeme, c)\n",
    "            if len(const1) > best_const_length and match(const1, lexeme):\n",
    "                best_const_length = len(const1)\n",
    "                best_const = const1\n",
    "#         print('best_const', best_const)\n",
    "        for c in glawi_constructions:\n",
    "            [const1, const2] = c.split('-')\n",
    "            if const1 != best_const:\n",
    "                continue\n",
    "            [prefix, postfix] = const1.split('X')\n",
    "            stem = lexeme.replace(prefix, '', 1)\n",
    "            if postfix:  # if not empty\n",
    "                stem = ''.join(stem.rsplit(postfix, 1))\n",
    "            new_lexeme = const2.replace('X', stem)\n",
    "            if new_lexeme in return_dict or new_lexeme in lexemes:\n",
    "                continue\n",
    "            try:\n",
    "                return_dict[new_lexeme] = cow_dict[new_lexeme]\n",
    "            except KeyError:\n",
    "                if new_lexeme in demonette_lexemes:\n",
    "                    return_dict[new_lexeme] = 0\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17593fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dir = 'demonette-glawinette_graph_binary'\n",
    "input_files = [f for f in listdir(binary_dir) if isfile(join(binary_dir, f))]\n",
    "input_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = codecs.open('DG_propositions_by_glawi.txt', 'w+', encoding='utf-8')\n",
    "for input_file in input_files:\n",
    "    print(input_file, end='\\r')\n",
    "    G = pickle.load(open(join(binary_dir, input_file), 'rb'))\n",
    "    output_file.write(input_file + '\\t' + str(generate_lexemes(G.nodes())) + '\\n')\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cf4fb",
   "metadata": {},
   "source": [
    "# reading vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069e94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149805\r"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with codecs.open('lemma-A-pos-bow.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        counter += 1\n",
    "        print(counter, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d8888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
