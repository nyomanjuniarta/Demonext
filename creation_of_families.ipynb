{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = 'pairs'\n",
    "input_files = dict()\n",
    "input_files['converts-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'A'\n",
    "input_files['demonette1-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'B'\n",
    "input_files['denomXaire-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'C'\n",
    "input_files['denomXal-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'D'\n",
    "input_files['denomXique-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'E'\n",
    "input_files['dimocXaie-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'F'\n",
    "input_files['dimocXat-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'G'\n",
    "input_files['dimocXet-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'H'\n",
    "input_files['dimocXier-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'I'\n",
    "input_files['derifde1X-formate-V4-nosem-utf8-lid-newtagset-entete-new-rid.csv'] = 'J'\n",
    "input_files['derifXable-formate-V4-nosem-utf8-lid-newtagset-entete-new-rid.csv'] = 'K'\n",
    "\n",
    "# column number\n",
    "graph_1 = 3\n",
    "graph_2 = 6\n",
    "cat_1 = 8\n",
    "cat_2 = 10\n",
    "cstr_1 = 14\n",
    "cstr_2 = 17\n",
    "complexite = 19\n",
    "orientation = 21\n",
    "fichier_origine = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = ''\n",
    "G = nx.DiGraph()\n",
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num == 0:\n",
    "                header = line.replace('\\n','')\n",
    "            elif line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                G.add_node(elements[graph_1] + '_' + elements[cat_1], label=elements[cat_1])\n",
    "                G.add_node(elements[graph_2] + '_' + elements[cat_2], label=elements[cat_2])\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    G.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=edge_type)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    G.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=edge_type)\n",
    "                else:\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type =  elements[complexite] + '_' + elements[orientation] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    G.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2],\\\n",
    "                               label=edge_type)\n",
    "                    G.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1],\\\n",
    "                               label=edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_comps = list(nx.weakly_connected_components(G))\n",
    "number_of_families = len(conn_comps)\n",
    "number_of_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█████████████████████████████████████████████████-| 99.99% complete\r"
     ]
    }
   ],
   "source": [
    "checked = list()\n",
    "H = nx.Graph() # graph of graphs\n",
    "for fam1 in range(0, number_of_families):\n",
    "    if fam1 in checked:\n",
    "        continue\n",
    "    H.add_node(fam1)\n",
    "    for fam2 in range(fam1 + 1, number_of_families):\n",
    "        if fam2 in checked:\n",
    "            continue\n",
    "        G1 = nx.subgraph(G, conn_comps[fam1])\n",
    "        G2 = nx.subgraph(G, conn_comps[fam2])\n",
    "        if nx.is_isomorphic(G1, G2, node_match=lambda v1,v2: v1['label'] == v2['label'],\\\n",
    "                            edge_match=lambda e1,e2: e1['label'] == e2['label']):\n",
    "            checked.append(fam2)\n",
    "            H.add_edge(fam1, fam2)\n",
    "    printProgressBar(fam1 + 1, number_of_families, prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3903\n"
     ]
    }
   ],
   "source": [
    "#H_conn_comps = list(nx.connected_components(H))\n",
    "H_conn_comps = [c for c in sorted(nx.connected_components(H), key=len, reverse=False)]\n",
    "print(len(H_conn_comps))\n",
    "#H_conn_comps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ajour_Nm', 'ajourage_Nm', 'ajourement_Nm', 'ajourer_V'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_comps[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_folder = 'families'\n",
    "lexeme_dict = dict()\n",
    "f_summary = codecs.open('summary_of_families.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('family_id\\tnumber_of_lexemes\\tlexemes\\n')\n",
    "for fam_fam_id, fam_fam in enumerate(H_conn_comps):\n",
    "    for fam_id, fam in enumerate(fam_fam):\n",
    "        # K = nx.subgraph(G, conn_comps[fam])\n",
    "        first_member = sorted(list(conn_comps[fam]))[0]\n",
    "        if len(fam_fam) == 1:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0')\n",
    "        else:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0') + '-' + str(fam_id).rjust(len(str(len(fam_fam)-1)), '0')\n",
    "        f_summary.write(family_title + '\\t'\\\n",
    "                       + str(len(conn_comps[fam])) + '\\t' + str(conn_comps[fam]) + '\\n')\n",
    "        for lexeme in conn_comps[fam]:\n",
    "            filename = family_title + ' ' + first_member + '.txt'\n",
    "            lexeme_dict[lexeme] = filename\n",
    "            f_out = codecs.open(join(output_folder, filename), 'w+', encoding='utf-8')\n",
    "            f_out.write(header + '\\tfichier_origine' + '\\n\\n')\n",
    "            f_out.close()\n",
    "f_summary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num < 2:\n",
    "                continue\n",
    "            elements = line.replace(' ','').split('\\t')\n",
    "            lexeme1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "            if elements[complexite] not in ['simple', 'complexe', 'motiv-form', 'motiv-sem', 'accidentel']:\n",
    "                print('warning ', input_file)\n",
    "            output_filename = lexeme_dict[lexeme1]\n",
    "            f_out = codecs.open(join(output_folder, output_filename), 'a+', encoding='utf-8')\n",
    "            f_out.write(line.strip('\\n') + '\\t' + input_files[input_file] + '\\n')\n",
    "            f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of double arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.01% complete\r"
     ]
    }
   ],
   "source": [
    "def reverse_direction(input_orientation):\n",
    "    if input_orientation == 'de2as':\n",
    "        input_orientation = 'as2de'\n",
    "    elif input_orientation == 'as2de':\n",
    "        input_orientation = 'de2as'\n",
    "    return input_orientation\n",
    "\n",
    "\n",
    "def line_writer(input_line):\n",
    "    elements = line.replace('\\n','').replace(' ','').replace('des2as', 'de2as').replace('as2des', 'as2de').split('\\t')\n",
    "    ret_line = elements[graph_1] + '\\t' + elements[cat_1] + '\\t' + elements[graph_2] + '\\t' + elements[cat_2] + '\\t'\\\n",
    "    + elements[orientation] + '\\t' + elements[complexite] + '\\t' + elements[cstr_1] + '\\t' + elements[cstr_2] + '\\t'\\\n",
    "    + elements[fichier_origine] + '\\n'\n",
    "    return ret_line\n",
    "\n",
    "\n",
    "f_duplicates = codecs.open('paires_doublons.txt', 'w+', encoding='utf-8')\n",
    "f_duplicates.write('graph_1\\tcat_1\\tgraph_2\\tcat_2\\torientation\\tcomplexite\\tcstr_1\\tcstr_2\\tfichier_origine\\n')\n",
    "input_dir = 'families'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "counter = 0\n",
    "for input_file in input_files:\n",
    "    G = nx.Graph()\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                reverse = False\n",
    "                elements = line.replace('\\n','').replace(' ','').replace('des2as', 'de2as').replace('as2des', 'as2de').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if v1 > v2:\n",
    "                    reverse = True\n",
    "                if reverse:\n",
    "                    edge_label = elements[complexite] + '_' + reverse_direction(elements[orientation]) + '_'\\\n",
    "                    + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                else:\n",
    "                    edge_label = elements[complexite] + '_' + elements[orientation] + '_' \\\n",
    "                    + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                if G.has_edge(v1, v2) and G[v1][v2]['label'] != edge_label and not G[v1][v2]['checked']:\n",
    "                    f_duplicates.write(G[v1][v2]['complete_line'])\n",
    "                    f_duplicates.write(line_writer(line) + '\\n')\n",
    "                    G[v1][v2]['checked'] = True\n",
    "                elif not G.has_edge(v1, v2):\n",
    "                    G.add_edge(v1, v2, label=edge_label, complete_line=line_writer(line), checked=False)\n",
    "    counter += 1\n",
    "    printProgressBar(counter + 1, len(input_files), prefix='Progress:', suffix='complete', length=50, decimals=2)\n",
    "f_duplicates.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Verification of families with non-connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13178\n"
     ]
    }
   ],
   "source": [
    "family_dict = dict()\n",
    "with codecs.open('summary_of_families.txt', 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num == 0:\n",
    "            continue\n",
    "        cols = line.split('\\t')\n",
    "        lexemes = cols[2].replace('{','').replace('}','').replace('\\'','').split(', ')\n",
    "        lexeme_set = set()\n",
    "        for lexeme in lexemes:\n",
    "            lexeme_set.add(lexeme.split('_')[0])\n",
    "        family_dict[cols[0]] = lexeme_set\n",
    "print(len(family_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "family_dict_keys = list(family_dict.keys())\n",
    "f_out = codecs.open('non-connected_families.txt', 'w+', encoding='utf-8')\n",
    "f_out.write('family_id_1\\tfamily_id_2\\tsuspected\\tlength_1\\tlength_2\\n')\n",
    "for k1 in range(0, len(family_dict)):\n",
    "    for k2 in range(k1+1, len(family_dict)):\n",
    "        set1 = family_dict[family_dict_keys[k1]]\n",
    "        set2 = family_dict[family_dict_keys[k2]]\n",
    "        connected = False\n",
    "        suspected = ''\n",
    "        for s1 in set1:\n",
    "            for s2 in set2:\n",
    "                if s1 in s2 or s2 in s1:\n",
    "                    suspected = s1 + '-' + s2 + '\\t' + str(len(s1)) + '\\t' + str(len(s2))\n",
    "                    connected = True\n",
    "                    break\n",
    "            if connected:\n",
    "                break\n",
    "        if connected:\n",
    "            f_out.write(family_dict_keys[k1] + '\\t' + family_dict_keys[k2] + '\\t' + suspected + '\\n')\n",
    "    printProgressBar(k1 + 1, len(family_dict), prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
