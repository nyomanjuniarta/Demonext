{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = 'pairs'\n",
    "input_files = dict()\n",
    "input_files['converts-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'A'\n",
    "input_files['demonette1-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'B'\n",
    "input_files['denomXaire-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'C'\n",
    "input_files['denomXal-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'D'\n",
    "input_files['denomXique-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'E'\n",
    "input_files['dimocXaie-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'F'\n",
    "input_files['dimocXat-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'G'\n",
    "input_files['dimocXet-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'H'\n",
    "input_files['dimocXier-formate-V4-avecsem-utf8-lid-newtagset-entete-new-rid.csv'] = 'I'\n",
    "input_files['derifde1X-formate-V4-nosem-utf8-lid-newtagset-entete-new-rid.csv'] = 'J'\n",
    "input_files['derifXable-formate-V4-nosem-utf8-lid-newtagset-entete-new-rid.csv'] = 'K'\n",
    "\n",
    "# column number\n",
    "graph_1 = 3\n",
    "graph_2 = 6\n",
    "cat_1 = 8\n",
    "cat_2 = 10\n",
    "cstr_1 = 14\n",
    "cstr_2 = 17\n",
    "complexite = 19\n",
    "orientation = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = ''\n",
    "G = nx.DiGraph()\n",
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num == 0:\n",
    "                header = line.replace('\\n','')\n",
    "            elif line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                G.add_node(elements[graph_1] + '_' + elements[cat_1], label=elements[cat_1])\n",
    "                G.add_node(elements[graph_2] + '_' + elements[cat_2], label=elements[cat_2])\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    G.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_type)\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[complexite] + '_' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    G.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_type)\n",
    "                else:\n",
    "                    sorted_cstr = sorted([elements[cstr_1], elements[cstr_2]])\n",
    "                    edge_type =  elements[complexite] + '_' + elements[orientation] + '_' + sorted_cstr[0] + '-' + sorted_cstr[1]\n",
    "                    G.add_edge(elements[graph_1] + '_' + elements[cat_1], elements[graph_2] + '_' + elements[cat_2], label=edge_type)\n",
    "                    G.add_edge(elements[graph_2] + '_' + elements[cat_2], elements[graph_1] + '_' + elements[cat_1], label=edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_comps = list(nx.weakly_connected_components(G))\n",
    "number_of_families = len(conn_comps)\n",
    "number_of_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█████████████████████████████████████████████████-| 99.99% complete\r"
     ]
    }
   ],
   "source": [
    "checked = list()\n",
    "H = nx.Graph() # graph of graphs\n",
    "for fam1 in range(0, number_of_families):\n",
    "    if fam1 in checked:\n",
    "        continue\n",
    "    H.add_node(fam1)\n",
    "    for fam2 in range(fam1 + 1, number_of_families):\n",
    "        if fam2 in checked:\n",
    "            continue\n",
    "        G1 = nx.subgraph(G, conn_comps[fam1])\n",
    "        G2 = nx.subgraph(G, conn_comps[fam2])\n",
    "        if nx.is_isomorphic(G1, G2, node_match=lambda v1,v2: v1['label'] == v2['label'],\\\n",
    "                            edge_match=lambda e1,e2: e1['label'] == e2['label']):\n",
    "            checked.append(fam2)\n",
    "            H.add_edge(fam1, fam2)\n",
    "    printProgressBar(fam1 + 1, number_of_families, prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3903\n"
     ]
    }
   ],
   "source": [
    "#H_conn_comps = list(nx.connected_components(H))\n",
    "H_conn_comps = [c for c in sorted(nx.connected_components(H), key=len, reverse=False)]\n",
    "print(len(H_conn_comps))\n",
    "#H_conn_comps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ajour_Nm', 'ajourage_Nm', 'ajourement_Nm', 'ajourer_V'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_comps[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_folder = 'families'\n",
    "lexeme_dict = dict()\n",
    "f_summary = codecs.open('summary_of_families.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('family_id\\tnumber_of_lexemes\\tlexemes\\n')\n",
    "for fam_fam_id, fam_fam in enumerate(H_conn_comps):\n",
    "    for fam_id, fam in enumerate(fam_fam):\n",
    "        # K = nx.subgraph(G, conn_comps[fam])\n",
    "        first_member = sorted(list(conn_comps[fam]))[0]\n",
    "        if len(fam_fam) == 1:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0')\n",
    "        else:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0') + '-' + str(fam_id).rjust(len(str(len(fam_fam)-1)), '0')\n",
    "        f_summary.write(family_title + '\\t'\\\n",
    "                       + str(len(conn_comps[fam])) + '\\t' + str(conn_comps[fam]) + '\\n')\n",
    "        for lexeme in conn_comps[fam]:\n",
    "            filename = family_title + ' ' + first_member + '.txt'\n",
    "            lexeme_dict[lexeme] = filename\n",
    "            f_out = codecs.open(join(output_folder, filename), 'w+', encoding='utf-8')\n",
    "            f_out.write(header + '\\tfichier_origine' + '\\n\\n')\n",
    "            f_out.close()\n",
    "f_summary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num < 2:\n",
    "                continue\n",
    "            elements = line.replace(' ','').split('\\t')\n",
    "            lexeme1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "            if elements[complexite] not in ['simple', 'complexe', 'motiv-form', 'motiv-sem', 'accidentel']:\n",
    "                print('warning ', input_file)\n",
    "            output_filename = lexeme_dict[lexeme1]\n",
    "            f_out = codecs.open(join(output_folder, output_filename), 'a+', encoding='utf-8')\n",
    "            f_out.write(line.strip('\\n') + '\\t' + input_files[input_file] + '\\n')\n",
    "            f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_file = open('G.p', 'wb')\n",
    "dict_file = open('lexeme_dict.p', 'wb')\n",
    "pickle.dump(G, graph_file)\n",
    "pickle.dump(lexeme_dict, dict_file)\n",
    "graph_file.close()\n",
    "dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
